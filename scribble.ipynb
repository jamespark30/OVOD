{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/work/ovdet', '/opt/conda/lib/python37.zip', '/opt/conda/lib/python3.7', '/opt/conda/lib/python3.7/lib-dynload', '', '/opt/conda/lib/python3.7/site-packages', '/opt/conda/lib/python3.7/site-packages/IPython/extensions', '/root/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "spanned_boxes = [torch.tensor([380.0980,   3.4500, 646.1620, 283.3370]), torch.tensor([140.6404,   3.4500, 646.1620, 535.2354]), torch.tensor([380.0980,   3.4500, 736.0000, 535.2354])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[380.0980,   3.4500, 646.1620, 283.3370]]), tensor([[140.6404,   3.4500, 646.1620, 535.2354]]), tensor([[380.0980,   3.4500, 736.0000, 535.2354]])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[380.0980,   3.4500, 646.1620, 283.3370, 140.6404,   3.4500, 646.1620,\n",
       "         535.2354, 380.0980,   3.4500, 736.0000, 535.2354]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanned_boxes = [box.unsqueeze(0) for box in spanned_boxes]\n",
    "print(spanned_boxes)\n",
    "torch.cat([box.unsqueeze(0) for box in spanned_boxes], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 텐서로 이루어진 리스트\n",
    "tensor_list = [torch.randn(2, 3), torch.randn(2, 3), torch.randn(2, 3)]\n",
    "\n",
    "# 리스트의 텐서들을 concat해서 하나의 텐서로 만듦 (dim=0을 기준으로 연결)\n",
    "result_tensor = torch.cat(tensor_list, dim=0)\n",
    "\n",
    "print(result_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def check_first_component_type(input_list):\n",
    "    first_component = input_list[0]\n",
    "    \n",
    "    if isinstance(first_component, list):\n",
    "        return \"list\"\n",
    "    elif isinstance(first_component, torch.Tensor):\n",
    "        return \"tensor\"\n",
    "    else:\n",
    "        return \"Neither list nor tensor\"\n",
    "\n",
    "# 예시\n",
    "my_list = [[torch.tensor([380.0980,   3.4500, 646.1620, 283.3370]), torch.tensor([140.6404,   3.4500, 646.1620, 535.2354]), torch.tensor([380.0980,   3.4500, 736.0000, 535.2354])], [torch.tensor([318.6765, 557.7500, 469.0505, 595.5160]), torch.tensor([183.3399, 523.7606, 469.0505, 595.5160]), torch.tensor([318.6765, 523.7606, 469.0505, 595.5160])], [torch.tensor([366.5165, 468.1075, 431.1120, 560.7285]), torch.tensor([308.3806, 384.7486, 431.1120, 560.7285]), torch.tensor([366.5165, 468.1075, 489.2479, 644.0873])]]\n",
    "my_list = [[torch.tensor([310.6100, 104.4954, 989.8538, 695.6575])]]\n",
    "print(check_first_component_type(my_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4], [3, 4, 6], [4, 8]]\n"
     ]
    }
   ],
   "source": [
    "def merge_unique_sorted(bbox):\n",
    "    # This will store the unique sorted lists\n",
    "    unique_sets = set()\n",
    "    merged_bbox = []\n",
    "    \n",
    "    for lst in bbox:\n",
    "        # Sort the list to normalize the order\n",
    "        sorted_lst = tuple(sorted(lst))  # Using tuple since lists are not hashable\n",
    "        if sorted_lst not in unique_sets:\n",
    "            unique_sets.add(sorted_lst)\n",
    "            merged_bbox.append(list(sorted_lst))  # Store sorted version\n",
    "\n",
    "    return merged_bbox\n",
    "\n",
    "# Example bbox input\n",
    "bbox = [[4], [6, 4, 3], [3, 6, 4], [8, 4], [4, 8]]\n",
    "\n",
    "# Perform the operation\n",
    "bbox2 = merge_unique_sorted(bbox)\n",
    "\n",
    "# Output the result\n",
    "print(bbox2)\n",
    "\n",
    "\n",
    "for box in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([[0.6429, 0.3214, 1.0000, 0.6786],\n",
    "                [0.3214, 0.6429, 0.6786, 1.0000],\n",
    "                [0.3214, 0.0000, 0.6786, 0.3571],\n",
    "                [0.3214, 0.3214, 0.6786, 0.6786],\n",
    "                [0.0000, 0.6429, 0.3571, 1.0000]])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5009/2866151567.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m bboxes: tensor([[380.0980,   3.4500, 646.1620, 283.3370],\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0;36m140.6404\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255.3483\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m406.7044\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m535.2354\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0;36m380.0980\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;36m3.4500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m646.1620\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m283.3370\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0;36m140.6404\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;36m3.4500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m406.7044\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m283.3370\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tensor' is not defined"
     ]
    }
   ],
   "source": [
    "<InstanceData(\n",
    "\n",
    "    META INFORMATION\n",
    "    normed_boxes: [[[tensor([[0.6429, 0.3214, 1.0000, 0.6786],\n",
    "                [0.3214, 0.6429, 0.6786, 1.0000],\n",
    "                [0.3214, 0.0000, 0.6786, 0.3571],\n",
    "                [0.3214, 0.3214, 0.6786, 0.6786],\n",
    "                [0.0000, 0.6429, 0.3571, 1.0000]]),\n",
    "                     \n",
    "                     tensor([[0.3214, 0.0000, 0.6786, 0.3571],\n",
    "                [0.3214, 0.6429, 0.6786, 1.0000],\n",
    "                [0.0000, 0.6429, 0.3571, 1.0000],\n",
    "                [0.3214, 0.3214, 0.6786, 0.6786],\n",
    "                [0.6429, 0.3214, 1.0000, 0.6786]])],\n",
    "                    \n",
    "                    [tensor([[0.0000, 0.0000, 0.3571, 1.0000],\n",
    "                [0.3214, 0.0000, 0.6786, 1.0000],\n",
    "                [0.6429, 0.0000, 1.0000, 1.0000]]),\n",
    "                     \n",
    "                     tensor([[0.0000, 0.0000, 0.3571, 1.0000],\n",
    "                [0.6429, 0.0000, 1.0000, 1.0000],\n",
    "                [0.3214, 0.0000, 0.6786, 1.0000]])],\n",
    "                    \n",
    "                    [tensor([[0.4737, 0.0000, 1.0000, 0.3571],\n",
    "                [0.4737, 0.3214, 1.0000, 0.6786],\n",
    "                [0.4737, 0.6429, 1.0000, 1.0000],\n",
    "                [0.0000, 0.3214, 0.5263, 0.6786]]),\n",
    "                     tensor([[0.4737, 0.6429, 1.0000, 1.0000],\n",
    "                [0.4737, 0.3214, 1.0000, 0.6786],\n",
    "                [0.0000, 0.3214, 0.5263, 0.6786],\n",
    "                [0.4737, 0.0000, 1.0000, 0.3571]])]],\n",
    "                   \n",
    "                   [[tensor([[0.3028, 0.0000, 0.6697, 0.3571],\n",
    "                [0.3028, 0.3214, 0.6697, 0.6786],\n",
    "                [0.6330, 0.6429, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 0.3395, 0.3571]]), tensor([[0.0000, 0.0000, 0.3395, 0.3571],\n",
    "                [0.6330, 0.6429, 1.0000, 1.0000],\n",
    "                [0.3028, 0.3214, 0.6697, 0.6786],\n",
    "                [0.3028, 0.0000, 0.6697, 0.3571]])], [tensor([[0.6330, 0.0000, 1.0000, 0.3571],\n",
    "                [0.3028, 0.3214, 0.6697, 0.6786],\n",
    "                [0.0000, 0.6429, 0.3395, 1.0000],\n",
    "                [0.0000, 0.3214, 0.3395, 0.6786]]), tensor([[0.3028, 0.3214, 0.6697, 0.6786],\n",
    "                [0.0000, 0.3214, 0.3395, 0.6786],\n",
    "                [0.0000, 0.6429, 0.3395, 1.0000],\n",
    "                [0.6330, 0.0000, 1.0000, 0.3571]])], [tensor([[0.0000, 0.4737, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 1.0000, 0.5263]]), tensor([[0.0000, 0.0000, 1.0000, 0.5263],\n",
    "                [0.0000, 0.4737, 1.0000, 1.0000]])]], [[tensor([[0.3214, 0.3214, 0.6786, 0.6786],\n",
    "                [0.6429, 0.6429, 1.0000, 1.0000],\n",
    "                [0.3214, 0.6429, 0.6786, 1.0000],\n",
    "                [0.0000, 0.0000, 0.3571, 0.3571],\n",
    "                [0.6429, 0.3214, 1.0000, 0.6786]]), tensor([[0.0000, 0.0000, 0.3571, 0.3571],\n",
    "                [0.6429, 0.3214, 1.0000, 0.6786],\n",
    "                [0.6429, 0.6429, 1.0000, 1.0000],\n",
    "                [0.3214, 0.3214, 0.6786, 0.6786],\n",
    "                [0.3214, 0.6429, 0.6786, 1.0000]])], [tensor([[0.0000, 0.6429, 0.3571, 1.0000],\n",
    "                [0.3214, 0.3214, 0.6786, 0.6786],\n",
    "                [0.0000, 0.0000, 0.3571, 0.3571],\n",
    "                [0.6429, 0.3214, 1.0000, 0.6786]]), tensor([[0.0000, 0.0000, 0.3571, 0.3571],\n",
    "                [0.3214, 0.3214, 0.6786, 0.6786],\n",
    "                [0.6429, 0.3214, 1.0000, 0.6786],\n",
    "                [0.0000, 0.6429, 0.3571, 1.0000]])], [tensor([[0., 0., 1., 1.]])]], [[tensor([[0.0000, 0.3214, 0.5263, 0.6786],\n",
    "                [0.4737, 0.0000, 1.0000, 0.3571],\n",
    "                [0.4737, 0.6429, 1.0000, 1.0000],\n",
    "                [0.4737, 0.3214, 1.0000, 0.6786]]), tensor([[0.4737, 0.0000, 1.0000, 0.3571],\n",
    "                [0.0000, 0.3214, 0.5263, 0.6786],\n",
    "                [0.4737, 0.6429, 1.0000, 1.0000],\n",
    "                [0.4737, 0.3214, 1.0000, 0.6786]])], [tensor([[0.4737, 0.0000, 1.0000, 0.3571],\n",
    "                [0.0000, 0.6429, 0.5263, 1.0000],\n",
    "                [0.4737, 0.3214, 1.0000, 0.6786]]), tensor([[0.0000, 0.6429, 0.5263, 1.0000],\n",
    "                [0.4737, 0.3214, 1.0000, 0.6786],\n",
    "                [0.4737, 0.0000, 1.0000, 0.3571]])], [tensor([[0., 0., 1., 1.]])]], [[tensor([[0.0000, 0.0000, 0.5263, 0.5263],\n",
    "                [0.0000, 0.4737, 0.5263, 1.0000],\n",
    "                [0.4737, 0.0000, 1.0000, 0.5263]]), tensor([[0.0000, 0.4737, 0.5263, 1.0000],\n",
    "                [0.0000, 0.0000, 0.5263, 0.5263],\n",
    "                [0.4737, 0.0000, 1.0000, 0.5263]])], [tensor([[0.3214, 0.3214, 0.6786, 0.6786],\n",
    "                [0.0000, 0.0000, 0.3571, 0.3571],\n",
    "                [0.6429, 0.6429, 1.0000, 1.0000],\n",
    "                [0.0000, 0.3214, 0.3571, 0.6786]]), tensor([[0.0000, 0.0000, 0.3571, 0.3571],\n",
    "                [0.0000, 0.3214, 0.3571, 0.6786],\n",
    "                [0.6429, 0.6429, 1.0000, 1.0000],\n",
    "                [0.3214, 0.3214, 0.6786, 0.6786]])], [tensor([[0.0000, 0.4737, 0.3571, 1.0000],\n",
    "                [0.3214, 0.0000, 0.6786, 0.5263],\n",
    "                [0.6429, 0.0000, 1.0000, 0.5263]]), tensor([[0.6429, 0.0000, 1.0000, 0.5263],\n",
    "                [0.0000, 0.4737, 0.3571, 1.0000],\n",
    "                [0.3214, 0.0000, 0.6786, 0.5263]])]]]\n",
    "    img_shape: (736, 1103)\n",
    "    pad_shape: (736, 1120)\n",
    "    img_id: 163128\n",
    "    img_path: '/work/ovdet/data/coco/train2017/000000163128.jpg'\n",
    "    spanned_boxes: [[tensor([185.1333, 129.9894, 585.2260, 638.9152]),\n",
    "                     tensor([185.1333, 293.5727, 585.2260, 475.3319]),\n",
    "                     tensor([313.7346, 129.9894, 585.2260, 638.9152])],\n",
    "                    \n",
    "                    [tensor([  0.0000, 117.9117, 409.5905, 626.0172]),\n",
    "                     tensor([  0.0000, 117.9117, 409.5905, 626.0172]),\n",
    "                     tensor([124.0186, 281.2313, 274.3195, 626.0172])],\n",
    "                    \n",
    "                    [tensor([304.4470,  88.1476, 818.4243, 717.9706]),\n",
    "                     tensor([304.4470,  88.1476, 818.4243, 717.9706]),\n",
    "                     tensor([469.6540, 290.5907, 653.2173, 515.5275])],\n",
    "                    \n",
    "                    [tensor([ 874.5239,   39.2528, 1077.5448,  337.1759]),\n",
    "                     tensor([778.3561,  39.2528, 981.3770, 337.1759]),\n",
    "                     tensor([874.5239, 135.0138, 981.3770, 241.4149])],\n",
    "                    \n",
    "                    [tensor([ 747.1447,  325.7877, 1078.5928,  688.4875]),\n",
    "                     tensor([ 590.1429,  153.9825, 1078.5928,  688.4875]),\n",
    "                     tensor([ 590.1429,  325.7877, 1078.5928,  688.4875])]]\n",
    "    box_ids: [[[5, 7, 1, 4, 6], [1, 7, 6, 4, 5], [3, 4, 5], [3, 5, 4], [2, 5, 8, 4], [8, 5, 4, 2]],\n",
    "              [[1, 4, 8, 0], [0, 8, 4, 1], [2, 4, 6, 3], [4, 3, 6, 2], [7, 4], [4, 7]],\n",
    "              [[4, 8, 7, 0, 5], [0, 5, 8, 4, 7], [6, 4, 0, 5], [0, 4, 5, 6], [4]],\n",
    "              [[4, 2, 8, 5], [2, 4, 8, 5], [1, 6, 4], [6, 4, 1], [4]],\n",
    "              [[4, 7, 5], [7, 4, 5], [4, 0, 8, 3], [0, 3, 8, 4], [6, 4, 5], [5, 6, 4]]]\n",
    "    ori_shape: (427, 640)\n",
    "    flip: False\n",
    "    scale_factor: (1.7234375, 1.7236533957845432)\n",
    "    batch_input_shape: (736, 1120)\n",
    "    flip_direction: None\n",
    "\n",
    "    DATA FIELDS\n",
    "    bboxes: tensor([\n",
    "                # 1st proposal\n",
    "                [ 442.3358,  293.5727,  585.2260,  475.3319],\n",
    "                [ 313.7346,  457.1559,  456.6248,  638.9152],\n",
    "                [ 313.7346,  129.9894,  456.6248,  311.7486],\n",
    "                [ 313.7346,  293.5727,  456.6248,  475.3319],\n",
    "                [ 185.1333,  457.1559,  328.0236,  638.9152],\n",
    "                \n",
    "                [ 313.7346,  129.9894,  456.6248,  311.7486],\n",
    "                [ 313.7346,  457.1559,  456.6248,  638.9152],\n",
    "                [ 185.1333,  457.1559,  328.0236,  638.9152],\n",
    "                [ 313.7346,  293.5727,  456.6248,  475.3319],\n",
    "                [ 442.3358,  293.5727,  585.2260,  475.3319],\n",
    "                \n",
    "                [ 185.1333,  293.5727,  328.0236,  475.3319],\n",
    "                [ 313.7346,  293.5727,  456.6248,  475.3319],\n",
    "                [ 442.3358,  293.5727,  585.2260,  475.3319],\n",
    "                \n",
    "                [ 185.1333,  293.5727,  328.0236,  475.3319],\n",
    "                [ 442.3358,  293.5727,  585.2260,  475.3319],\n",
    "                [ 313.7346,  293.5727,  456.6248,  475.3319],\n",
    "                \n",
    "                [ 442.3358,  129.9894,  585.2260,  311.7486],\n",
    "                [ 442.3358,  293.5727,  585.2260,  475.3319],\n",
    "                [ 442.3358,  457.1559,  585.2260,  638.9152],\n",
    "                [ 313.7346,  293.5727,  456.6248,  475.3319],\n",
    "                \n",
    "                [ 442.3358,  457.1559,  585.2260,  638.9152],\n",
    "                [ 442.3358,  293.5727,  585.2260,  475.3319],\n",
    "                [ 313.7346,  293.5727,  456.6248,  475.3319],\n",
    "                [ 442.3358,  129.9894,  585.2260,  311.7486],\n",
    "                \n",
    "                # 2nd proposal\n",
    "                [ 124.0186,  117.9117,  274.3195,  299.3779],\n",
    "                [ 124.0186,  281.2313,  274.3195,  462.6975],\n",
    "                [ 259.2895,  444.5509,  409.5905,  626.0172],\n",
    "                [   0.0000,  117.9117,  139.0487,  299.3779],\n",
    "                \n",
    "                [   0.0000,  117.9117,  139.0487,  299.3779],\n",
    "                [ 259.2895,  444.5509,  409.5905,  626.0172],\n",
    "                [ 124.0186,  281.2313,  274.3195,  462.6975],\n",
    "                [ 124.0186,  117.9117,  274.3195,  299.3779],\n",
    "                \n",
    "                [ 259.2895,  117.9117,  409.5905,  299.3779],\n",
    "                [ 124.0186,  281.2313,  274.3195,  462.6975],\n",
    "                [   0.0000,  444.5509,  139.0487,  626.0172],\n",
    "                [   0.0000,  281.2313,  139.0487,  462.6975],\n",
    "                \n",
    "                [ 124.0186,  281.2313,  274.3195,  462.6975],\n",
    "                [   0.0000,  281.2313,  139.0487,  462.6975],\n",
    "                [   0.0000,  444.5509,  139.0487,  626.0172],\n",
    "                [ 259.2895,  117.9117,  409.5905,  299.3779],\n",
    "                \n",
    "                [ 124.0186,  444.5509,  274.3195,  626.0172],\n",
    "                [ 124.0186,  281.2313,  274.3195,  462.6975],\n",
    "                \n",
    "                [ 124.0186,  281.2313,  274.3195,  462.6975],\n",
    "                [ 124.0186,  444.5509,  274.3195,  626.0172],\n",
    "                \n",
    "                # 3rd proposal\n",
    "                [ 469.6540,  290.5907,  653.2173,  515.5275],\n",
    "                [ 634.8610,  493.0338,  818.4243,  717.9706],\n",
    "                [ 469.6540,  493.0338,  653.2173,  717.9706],\n",
    "                [ 304.4470,   88.1476,  488.0103,  313.0844],\n",
    "                [ 634.8610,  290.5907,  818.4243,  515.5275],\n",
    "                \n",
    "                [ 304.4470,   88.1476,  488.0103,  313.0844],\n",
    "                [ 634.8610,  290.5907,  818.4243,  515.5275],\n",
    "                [ 634.8610,  493.0338,  818.4243,  717.9706],\n",
    "                [ 469.6540,  290.5907,  653.2173,  515.5275],\n",
    "                [ 469.6540,  493.0338,  653.2173,  717.9706],\n",
    "                \n",
    "                [ 304.4470,  493.0338,  488.0103,  717.9706],\n",
    "                [ 469.6540,  290.5907,  653.2173,  515.5275],\n",
    "                [ 304.4470,   88.1476,  488.0103,  313.0844],\n",
    "                [ 634.8610,  290.5907,  818.4243,  515.5275],\n",
    "                \n",
    "                [ 304.4470,   88.1476,  488.0103,  313.0844],\n",
    "                [ 469.6540,  290.5907,  653.2173,  515.5275],\n",
    "                [ 634.8610,  290.5907,  818.4243,  515.5275],\n",
    "                [ 304.4470,  493.0338,  488.0103,  717.9706],\n",
    "                \n",
    "                [ 469.6540,  290.5907,  653.2173,  515.5275],\n",
    "                \n",
    "                # 4th proposal\n",
    "                [ 874.5239,  135.0138,  981.3770,  241.4149],\n",
    "                [ 970.6917,   39.2528, 1077.5448,  145.6539],\n",
    "                [ 970.6917,  230.7748, 1077.5448,  337.1759],\n",
    "                [ 970.6917,  135.0138, 1077.5448,  241.4149],\n",
    "                \n",
    "                [ 970.6917,   39.2528, 1077.5448,  145.6539],\n",
    "                [ 874.5239,  135.0138,  981.3770,  241.4149],\n",
    "                [ 970.6917,  230.7748, 1077.5448,  337.1759],\n",
    "                [ 970.6917,  135.0138, 1077.5448,  241.4149],\n",
    "                \n",
    "                [ 874.5239,   39.2528,  981.3770,  145.6539],\n",
    "                [ 778.3561,  230.7748,  885.2092,  337.1759],\n",
    "                [ 874.5239,  135.0138,  981.3770,  241.4149],\n",
    "                \n",
    "                [ 778.3561,  230.7748,  885.2092,  337.1759],\n",
    "                [ 874.5239,  135.0138,  981.3770,  241.4149],\n",
    "                [ 874.5239,   39.2528,  981.3770,  145.6539],\n",
    "                \n",
    "                [ 874.5239,  135.0138,  981.3770,  241.4149],\n",
    "                \n",
    "                # 5th proposal\n",
    "                [ 747.1447,  325.7877,  921.5910,  516.6824],\n",
    "                [ 747.1447,  497.5929,  921.5910,  688.4875],\n",
    "                [ 904.1464,  325.7877, 1078.5928,  516.6824],\n",
    "                [ 747.1447,  497.5929,  921.5910,  688.4875],\n",
    "                [ 747.1447,  325.7877,  921.5910,  516.6824],\n",
    "                [ 904.1464,  325.7877, 1078.5928,  516.6824],\n",
    "                [ 747.1447,  325.7877,  921.5910,  516.6824],\n",
    "                [ 590.1429,  153.9825,  764.5893,  344.8772],\n",
    "                [ 904.1464,  497.5929, 1078.5928,  688.4875],\n",
    "                [ 590.1429,  325.7877,  764.5893,  516.6824],\n",
    "                [ 590.1429,  153.9825,  764.5893,  344.8772],\n",
    "                [ 590.1429,  325.7877,  764.5893,  516.6824],\n",
    "                [ 904.1464,  497.5929, 1078.5928,  688.4875],\n",
    "                [ 747.1447,  325.7877,  921.5910,  516.6824],\n",
    "                [ 590.1429,  497.5929,  764.5893,  688.4875],\n",
    "                [ 747.1447,  325.7877,  921.5910,  516.6824],\n",
    "                [ 904.1464,  325.7877, 1078.5928,  516.6824],\n",
    "                [ 904.1464,  325.7877, 1078.5928,  516.6824],\n",
    "                [ 590.1429,  497.5929,  764.5893,  688.4875],\n",
    "                [ 747.1447,  325.7877,  921.5910,  516.6824]], device='cuda:0')\n",
    ") at 0x7f95cb9f5410>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_boxes =  [[[tensor([[0.6429, 0.0000, 1.0000, 1.0000],\n",
    "                [0.3214, 0.0000, 0.6786, 1.0000],\n",
    "                [0.0000, 0.0000, 0.3571, 1.0000]]),\n",
    "                   tensor([[0.3214, 0.0000, 0.6786, 1.0000],\n",
    "                [0.6429, 0.0000, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 0.3571, 1.0000]])],\n",
    "                  \n",
    "                  [tensor([[0.0000, 0.0000, 0.5263, 1.0000],\n",
    "                [0.4737, 0.0000, 1.0000, 1.0000]]),\n",
    "                   tensor([[0.4737, 0.0000, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 0.5263, 1.0000]])],\n",
    "                  \n",
    "                  [tensor([[0., 0., 1., 1.]])]]]\n",
    "\n",
    "[[tensor([247.7317, 246.8107, 545.8994, 521.3120]),\n",
    "  tensor([247.7317, 246.8107, 450.0598, 521.3120]),\n",
    "  tensor([343.5713, 246.8107, 450.0598, 521.3120])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([ 27.6607, 555.8445, 539.8071, 697.0411]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 15.3500, 308.3200, 299.5600, 386.6400],\n",
      "        [ 15.3500, 237.8320, 299.5600, 316.1520],\n",
      "        [ 15.3500, 308.3200, 299.5600, 386.6400],\n",
      "        [ 15.3500, 308.3200, 299.5600, 386.6400],\n",
      "        [ 15.3500, 237.8320, 299.5600, 316.1520],\n",
      "        [271.1390, 378.8080, 500.0000, 426.0000],\n",
      "        [ 15.3500, 308.3200, 299.5600, 386.6400],\n",
      "        [ 15.3500, 308.3200, 299.5600, 386.6400],\n",
      "        [271.1390, 378.8080, 500.0000, 426.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 주어진 텐서\n",
    "tensor = torch.Tensor([[ 27.6607, 555.8445, 539.8071, 697.0411],\n",
    "                       [ 27.6607, 428.7675, 539.8071, 569.9642],\n",
    "                       [ 27.6607, 555.8445, 539.8071, 697.0411],\n",
    "                       [ 27.6607, 555.8445, 539.8071, 697.0411],\n",
    "                       [ 27.6607, 428.7675, 539.8071, 569.9642],\n",
    "                       [488.5925, 682.9215, 901.0000, 768.0000],\n",
    "                       [ 27.6607, 555.8445, 539.8071, 697.0411],\n",
    "                       [ 27.6607, 555.8445, 539.8071, 697.0411],\n",
    "                       [488.5925, 682.9215, 901.0000, 768.0000]]).to('cuda:0')\n",
    "\n",
    "# scale factor\n",
    "scale_factor_x, scale_factor_y = (1.802, 1.8028169014084507)\n",
    "\n",
    "# x 좌표에 scale_factor_x로 나누고 y 좌표에 scale_factor_y로 나누기\n",
    "tensor_scaled = tensor.clone()  # 원본 텐서를 수정하지 않기 위해 복사\n",
    "tensor_scaled[:, [0, 2]] /= scale_factor_x  # x_min, x_max\n",
    "tensor_scaled[:, [1, 3]] /= scale_factor_y  # y_min, y_max\n",
    "\n",
    "print(tensor_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'cls_score': tensor([[17.7719,  6.7329,  8.3024,  ...,  7.4082,  3.1290, 11.3706],\n",
    "        [ 3.6786,  1.5085,  2.0590,  ...,  3.5874,  5.6282, 13.7622],\n",
    "        [16.6988,  4.9374,  6.6151,  ...,  5.6429,  1.5098, 11.6465],\n",
    "        ...,\n",
    "        [ 7.6765,  1.2194,  2.1984,  ...,  4.5045, -0.2120, 13.9624],\n",
    "        [ 5.0709,  2.3036,  1.4480,  ...,  4.8839, -1.1853, 11.5938],\n",
    "        [ 7.2381,  0.2605,  1.0862,  ...,  1.1516, -2.4484, 14.2690]],\n",
    "       device='cuda:0'), 'bbox_pred': tensor([[-7.7563e-04,  9.8348e-04,  5.7950e-03,  1.3278e-02],\n",
    "        [-2.4459e+00, -5.6515e-01,  7.5680e-01, -4.5752e-01],\n",
    "        [ 5.6874e-01, -3.0446e-01, -1.2812e+00, -2.6625e-01],\n",
    "        ...,\n",
    "        [ 1.3134e+00,  1.6436e+00,  4.5726e-01,  2.2817e-01],\n",
    "        [-3.4432e-03,  1.5936e-01, -1.4160e-01, -9.9852e-02],\n",
    "        [ 9.3554e-01, -1.0223e+00,  4.1643e-01, -6.2520e-01]], device='cuda:0'), 'bbox_feats': tensor([[[[ 2.2681e-01,  3.0949e-01,  3.0893e-01,  ...,  1.4209e-01,\n",
    "            1.6857e-01,  1.6345e-01],\n",
    "          [ 3.5429e-01,  4.3373e-01,  4.3064e-01,  ...,  2.5761e-01,\n",
    "            2.9156e-01,  3.5900e-01],\n",
    "          [ 7.9172e-01,  7.6667e-01,  5.2601e-01,  ...,  3.2142e-01,\n",
    "            5.7765e-01,  7.7989e-01],\n",
    "          ...,\n",
    "          [ 7.3292e-01,  8.9239e-01,  8.2438e-01,  ...,  8.5121e-01,\n",
    "            1.0027e+00,  1.0900e+00],\n",
    "          [ 9.4223e-01,  1.1112e+00,  1.2156e+00,  ...,  1.0403e+00,\n",
    "            9.6613e-01,  9.4445e-01],\n",
    "          [ 1.3128e+00,  1.3787e+00,  1.3604e+00,  ...,  1.3920e+00,\n",
    "            1.3690e+00,  1.2437e+00]],\n",
    "\n",
    "         [[-3.4412e-01,  2.3636e-02,  2.9722e-01,  ...,  1.0457e-01,\n",
    "           -2.3849e-01, -3.7024e-01],\n",
    "          [-4.7141e-01,  9.9370e-03,  2.0302e-01,  ...,  1.4786e-02,\n",
    "           -3.4467e-01, -6.6257e-01],\n",
    "          [-3.8571e-01,  1.7151e-02,  2.0229e-01,  ...,  5.4771e-02,\n",
    "            6.3643e-02, -6.0541e-02],\n",
    "          ...,\n",
    "          [ 5.0381e-01,  6.9006e-01,  6.2704e-01,  ...,  2.5733e-01,\n",
    "            1.6617e-01,  1.1966e-01],\n",
    "          [ 3.4706e-01,  8.8073e-01,  8.2981e-01,  ...,  5.3134e-01,\n",
    "            2.1907e-01,  1.7309e-01],\n",
    "          [-8.3698e-02,  1.6941e-01,  5.5063e-01,  ...,  1.1635e-01,\n",
    "           -1.5774e-01,  1.3666e-01]],\n",
    "\n",
    "         [[ 5.2667e-02, -3.5099e-02,  9.3003e-02,  ...,  1.9821e-01,\n",
    "            4.0304e-02,  3.3406e-02],\n",
    "          [-6.6346e-02,  1.3342e-01,  2.9694e-01,  ...,  7.4272e-02,\n",
    "           -8.8502e-02, -1.2536e-01],\n",
    "          [-4.1238e-03,  1.8303e-01,  1.8962e-01,  ...,  1.2147e-01,\n",
    "            1.8103e-01,  3.1393e-02],\n",
    "          ...,\n",
    "          [ 9.2398e-03,  3.5505e-01,  3.6918e-01,  ...,  2.5626e-01,\n",
    "            1.5049e-01,  1.7259e-01],\n",
    "          [-1.5183e-01,  2.3349e-01,  1.9580e-01,  ..., -1.6205e-02,\n",
    "           -1.0492e-01,  1.3584e-01],\n",
    "          [-2.5317e-01, -1.4259e-01, -2.0678e-01,  ..., -3.9657e-01,\n",
    "           -4.3021e-01, -2.9203e-01]],\n",
    "\n",
    "         ...,\n",
    "\n",
    "         [[-6.5358e-01, -5.5088e-01, -2.3758e-01,  ..., -4.5644e-01,\n",
    "           -4.2728e-01, -2.2847e-01],\n",
    "          [-3.1472e-01, -3.0101e-02,  5.1330e-02,  ...,  8.8320e-02,\n",
    "            1.7891e-01, -4.9309e-02],\n",
    "          [-1.9096e-01,  1.0374e-02,  2.1325e-01,  ...,  3.8756e-01,\n",
    "            3.8604e-01, -4.6211e-02],\n",
    "          ...,\n",
    "          [ 2.5691e-02,  4.0932e-01,  6.9423e-01,  ...,  5.7530e-01,\n",
    "            1.8413e-01, -1.1990e-01],\n",
    "          [ 3.2251e-01,  6.8442e-01,  9.3347e-01,  ...,  8.5847e-01,\n",
    "            5.1168e-01,  3.1893e-01],\n",
    "          [ 2.4605e-01,  4.3417e-01,  9.1465e-01,  ...,  7.9999e-01,\n",
    "            5.0606e-01,  4.3953e-01]],\n",
    "\n",
    "         [[ 8.6039e-02, -2.5230e-01, -7.9076e-01,  ..., -9.8684e-01,\n",
    "           -5.6361e-01, -2.5849e-01],\n",
    "          [-6.0883e-02, -2.5046e-01, -3.9643e-01,  ..., -3.2166e-01,\n",
    "           -3.7933e-01, -2.4124e-01],\n",
    "          [-1.9541e-01, -1.0398e-01, -8.8660e-02,  ...,  2.4788e-01,\n",
    "            2.6839e-02, -6.0043e-02],\n",
    "          ...,\n",
    "          [-5.3729e-02,  3.0658e-02, -3.9640e-02,  ...,  1.9628e-01,\n",
    "            2.1033e-01, -4.6742e-02],\n",
    "          [-1.1396e-02,  1.7238e-01,  2.0707e-02,  ...,  1.9186e-01,\n",
    "            1.2553e-01,  2.1105e-02],\n",
    "          [ 1.6139e-01,  2.7259e-01,  1.1439e-01,  ...,  1.7937e-01,\n",
    "            1.5641e-01,  9.3468e-03]],\n",
    "\n",
    "         [[ 1.1898e+00,  1.4662e+00,  1.5053e+00,  ..., -1.6716e-02,\n",
    "           -6.5577e-01, -3.0758e-01],\n",
    "          [ 3.1560e-01, -4.8692e-01,  2.5871e-02,  ...,  3.5030e-01,\n",
    "           -6.1167e-01, -4.1327e-01],\n",
    "          [-1.3032e+00, -8.8598e-01, -1.2088e-01,  ...,  1.9970e-01,\n",
    "            8.1398e-01, -1.5559e-01],\n",
    "          ...,\n",
    "          [-1.3657e-01, -3.3270e-01,  3.6109e-01,  ...,  1.1165e+00,\n",
    "            4.9724e-01,  2.1955e-01],\n",
    "          [-5.0936e-01, -5.2797e-01,  3.1769e-01,  ...,  6.9618e-01,\n",
    "            1.6829e-02,  3.6412e-01],\n",
    "          [-9.2053e-01, -7.9888e-01, -2.0754e-02,  ...,  5.2269e-01,\n",
    "            8.4206e-02, -3.8430e-01]]],\n",
    "\n",
    "\n",
    "        [[[-1.6479e-01, -2.2477e-01, -3.0824e-01,  ..., -4.0324e-01,\n",
    "           -4.8099e-01, -4.2473e-01],\n",
    "          [-1.5766e-02, -1.0320e-01, -2.3029e-01,  ..., -3.6190e-01,\n",
    "           -4.1614e-01, -3.1992e-01],\n",
    "          [-1.8988e-03, -7.4463e-02, -1.0972e-01,  ..., -1.2669e-01,\n",
    "           -1.0750e-01, -5.9270e-02],\n",
    "          ...,\n",
    "          [-1.1282e-01, -1.5509e-01, -1.2972e-01,  ...,  2.7914e-02,\n",
    "            2.5035e-01,  2.3900e-01],\n",
    "          [-6.9262e-02, -7.2948e-02, -1.3376e-01,  ..., -1.7108e-01,\n",
    "            6.8062e-02,  1.0203e-01],\n",
    "          [ 8.2277e-02,  7.4263e-02,  3.8620e-02,  ..., -1.2909e-02,\n",
    "            6.4695e-02,  4.8646e-02]],\n",
    "\n",
    "         [[-4.8248e-01, -3.3078e-01, -2.6195e-01,  ..., -3.2817e-01,\n",
    "           -2.6833e-01, -2.4339e-01],\n",
    "          [ 3.3781e-01,  3.4631e-01,  2.3820e-01,  ...,  2.3267e-01,\n",
    "            3.4119e-01,  2.5967e-01],\n",
    "          [-6.0388e-02, -8.5387e-02,  2.3043e-02,  ...,  3.5240e-01,\n",
    "            4.9938e-01,  4.4724e-01],\n",
    "          ...,\n",
    "          [-7.6436e-01, -8.7539e-01, -8.0385e-01,  ..., -5.8906e-01,\n",
    "           -4.6014e-01, -4.1205e-01],\n",
    "          [ 3.8752e-01,  5.1705e-01,  3.6069e-01,  ..., -1.1778e-01,\n",
    "           -4.1326e-01, -4.3516e-01],\n",
    "          [-6.8677e-01, -6.2556e-01, -5.9398e-01,  ..., -5.4500e-01,\n",
    "           -5.7315e-01, -7.1066e-01]],\n",
    "\n",
    "         [[-3.9130e-01, -4.0811e-01, -4.8143e-01,  ..., -4.5394e-01,\n",
    "           -3.9754e-01, -3.6403e-01],\n",
    "          [-1.0831e-01, -1.4821e-01, -2.5563e-01,  ..., -2.8657e-01,\n",
    "           -3.2023e-01, -2.7746e-01],\n",
    "          [-1.6404e-01, -1.9367e-01, -1.3654e-01,  ..., -6.5891e-02,\n",
    "           -4.8783e-02,  2.0304e-03],\n",
    "          ...,\n",
    "          [-6.8320e-02, -8.7893e-02,  1.1343e-02,  ...,  1.1399e-01,\n",
    "            2.7449e-01,  3.2004e-01],\n",
    "          [ 2.1307e-01,  2.5936e-01,  2.6058e-01,  ...,  1.8602e-01,\n",
    "            1.8538e-01,  1.6338e-01],\n",
    "          [ 2.7445e-02,  3.3792e-02,  4.5786e-02,  ...,  2.2628e-02,\n",
    "            2.9059e-02,  3.3665e-02]],\n",
    "\n",
    "         ...,\n",
    "\n",
    "         [[ 1.3848e-01,  1.8745e-01,  1.4238e-01,  ..., -2.9159e-02,\n",
    "           -8.4937e-02, -1.2740e-01],\n",
    "          [ 2.8930e-02,  8.2404e-02,  5.6489e-02,  ...,  1.9204e-03,\n",
    "           -1.8299e-02, -4.6277e-02],\n",
    "          [ 1.4303e-01,  2.0121e-01,  1.9411e-01,  ...,  1.9057e-01,\n",
    "            1.4695e-01,  1.4803e-01],\n",
    "          ...,\n",
    "          [ 1.2642e-01,  1.5518e-01,  1.5895e-01,  ...,  4.2944e-02,\n",
    "           -5.9482e-02, -8.4114e-03],\n",
    "          [-5.0715e-02, -5.1684e-02,  1.4542e-02,  ...,  6.0197e-02,\n",
    "            1.9410e-02,  7.2557e-02],\n",
    "          [-5.6290e-02, -4.2914e-02,  1.8894e-02,  ...,  1.8338e-01,\n",
    "            2.4295e-01,  1.8998e-01]],\n",
    "\n",
    "         [[-2.7949e-01, -3.6227e-01, -4.0313e-01,  ..., -3.0678e-01,\n",
    "           -2.4576e-01, -2.1528e-01],\n",
    "          [-8.3125e-02, -1.6045e-01, -1.3552e-01,  ...,  6.5249e-02,\n",
    "            1.8201e-01,  2.0588e-01],\n",
    "          [-3.6479e-01, -3.4349e-01, -2.3291e-01,  ..., -1.3906e-01,\n",
    "           -4.3308e-02, -4.4745e-02],\n",
    "          ...,\n",
    "          [-3.8667e-01, -3.4058e-01, -3.5895e-01,  ..., -1.9610e-01,\n",
    "            6.0507e-02,  1.0089e-01],\n",
    "          [-6.4776e-03,  9.8521e-02, -3.6365e-02,  ..., -1.8713e-01,\n",
    "           -1.1289e-01, -8.4182e-02],\n",
    "          [-1.3028e-01, -7.6646e-02, -1.9800e-01,  ..., -4.0678e-01,\n",
    "           -4.6130e-01, -4.5325e-01]],\n",
    "\n",
    "         [[ 7.4509e-02, -1.1185e-01,  4.2798e-01,  ...,  3.1548e-01,\n",
    "            4.5712e-02,  1.2571e-01],\n",
    "          [ 8.6675e-01,  8.0364e-01,  1.0309e+00,  ...,  7.6451e-01,\n",
    "            1.0220e+00,  9.7462e-01],\n",
    "          [ 6.7239e-01,  1.0342e+00,  1.0354e+00,  ...,  7.8174e-01,\n",
    "            1.0236e+00,  6.4322e-01],\n",
    "          ...,\n",
    "          [ 1.4337e-01,  1.5566e-01, -2.5734e-01,  ..., -2.7684e-02,\n",
    "            1.2399e-01,  9.4872e-02],\n",
    "          [ 1.5058e+00,  1.2505e+00,  8.9671e-01,  ...,  1.3277e+00,\n",
    "            1.4650e+00,  1.3766e+00],\n",
    "          [-2.1461e-02,  8.1034e-02,  7.4582e-02,  ...,  7.0346e-01,\n",
    "            1.0013e+00,  9.1851e-01]]],\n",
    "\n",
    "\n",
    "        [[[ 2.2589e-01,  2.6564e-01,  3.0109e-01,  ...,  1.2757e-01,\n",
    "            1.7575e-01,  2.3036e-01],\n",
    "          [ 4.5460e-01,  4.0615e-01,  4.4002e-01,  ...,  2.4987e-01,\n",
    "            3.1765e-01,  4.1690e-01],\n",
    "          [ 4.4096e-01,  6.9060e-01,  8.1588e-01,  ...,  2.7282e-01,\n",
    "            5.5843e-01,  8.6576e-01],\n",
    "          ...,\n",
    "          [ 6.1991e-01,  6.2108e-01,  9.0322e-01,  ...,  8.9947e-01,\n",
    "            9.6613e-01,  9.8568e-01],\n",
    "          [ 8.8353e-01,  1.0294e+00,  1.2291e+00,  ...,  1.2046e+00,\n",
    "            1.1792e+00,  9.7245e-01],\n",
    "          [ 1.2315e+00,  1.4624e+00,  1.5442e+00,  ...,  1.4328e+00,\n",
    "            1.4878e+00,  1.3383e+00]],\n",
    "\n",
    "         [[-6.3203e-01, -4.9201e-01, -1.0373e-01,  ...,  1.5491e-01,\n",
    "           -2.1254e-01, -4.4640e-01],\n",
    "          [-4.6965e-01, -5.9528e-01, -1.1045e-01,  ...,  1.0620e-01,\n",
    "           -3.1942e-01, -6.4940e-01],\n",
    "          [-4.2651e-01, -3.8461e-01, -2.8179e-03,  ...,  2.3806e-01,\n",
    "            5.3090e-02, -5.3020e-02],\n",
    "          ...,\n",
    "          [ 7.6832e-02,  3.2725e-01,  8.7299e-01,  ...,  4.2452e-01,\n",
    "            2.2410e-01,  2.1752e-01],\n",
    "          [ 7.8363e-02, -1.2477e-01,  4.3012e-01,  ...,  5.2475e-01,\n",
    "            1.1000e-01,  2.4842e-01],\n",
    "          [-2.1575e-01, -3.1826e-01, -9.5922e-02,  ..., -6.1855e-02,\n",
    "           -2.8050e-01, -1.2971e-01]],\n",
    "\n",
    "         [[-1.0844e-01,  5.5636e-02, -2.0899e-02,  ...,  1.6876e-01,\n",
    "            4.6626e-02,  5.9222e-02],\n",
    "          [-5.0422e-02, -4.6782e-02,  9.8710e-02,  ...,  1.6878e-01,\n",
    "           -4.0898e-02, -1.5325e-01],\n",
    "          [ 1.4281e-01,  1.0760e-01,  7.9125e-02,  ...,  2.6746e-02,\n",
    "            9.0279e-02,  2.2729e-02],\n",
    "          ...,\n",
    "          [-1.5733e-01, -2.6095e-01,  2.3350e-01,  ...,  1.8721e-01,\n",
    "            4.8681e-02,  2.7867e-01],\n",
    "          [-2.5274e-01, -2.7540e-01,  7.7397e-02,  ..., -1.3318e-01,\n",
    "           -1.8883e-01,  5.4282e-02],\n",
    "          [-9.5637e-02, -2.8216e-01, -2.1652e-01,  ..., -3.7900e-01,\n",
    "           -3.6945e-01, -1.6308e-01]],\n",
    "\n",
    "         ...,\n",
    "\n",
    "         [[-7.4769e-01, -5.9098e-01, -6.0922e-01,  ..., -3.5733e-01,\n",
    "           -4.5642e-01, -2.4158e-01],\n",
    "          [-3.5414e-01, -4.0931e-01, -7.6252e-02,  ...,  2.7229e-02,\n",
    "            1.7170e-01, -7.3335e-02],\n",
    "          [-2.4747e-01, -2.5618e-01, -3.0287e-02,  ...,  3.6182e-01,\n",
    "            3.5254e-01, -1.6622e-01],\n",
    "          ...,\n",
    "          [ 2.4102e-01,  8.3026e-02,  5.7189e-01,  ...,  8.3874e-01,\n",
    "            3.0624e-01, -2.9120e-02],\n",
    "          [ 3.6541e-01,  2.4972e-01,  4.2316e-01,  ...,  1.0361e+00,\n",
    "            6.2133e-01,  4.2754e-01],\n",
    "          [ 3.2423e-01,  8.5875e-02,  1.6689e-01,  ...,  3.9193e-01,\n",
    "            1.3554e-01,  4.6249e-02]],\n",
    "\n",
    "         [[-7.0803e-04, -3.0675e-02, -1.1443e-01,  ..., -9.9231e-01,\n",
    "           -5.5453e-01, -2.4727e-01],\n",
    "          [ 8.1465e-02, -6.3177e-02, -1.8157e-01,  ..., -2.1439e-01,\n",
    "           -3.3996e-01, -2.2619e-01],\n",
    "          [ 7.8630e-02, -1.5310e-01, -1.0031e-01,  ...,  2.0215e-01,\n",
    "            4.1832e-02, -6.1656e-02],\n",
    "          ...,\n",
    "          [-1.4250e-01, -1.0010e-01,  2.8685e-02,  ...,  1.3437e-01,\n",
    "            1.8477e-01, -1.1442e-01],\n",
    "          [-4.6055e-01, -1.7561e-01,  2.8030e-01,  ...,  1.9161e-01,\n",
    "            1.5465e-01, -9.3725e-02],\n",
    "          [-3.4850e-01, -1.4808e-01,  8.4196e-02,  ..., -4.1734e-02,\n",
    "            3.5366e-02, -9.5125e-02]],\n",
    "\n",
    "         [[ 4.6223e-01,  8.2413e-01,  1.3737e+00,  ...,  3.8411e-01,\n",
    "           -6.2135e-01, -2.2820e-01],\n",
    "          [ 7.2403e-01,  5.4372e-01, -4.3206e-01,  ...,  5.7083e-01,\n",
    "           -4.4570e-01, -2.1293e-01],\n",
    "          [ 3.1162e-02, -3.0648e-01, -9.4645e-01,  ..., -4.3127e-02,\n",
    "            5.4787e-01, -1.4089e-01],\n",
    "          ...,\n",
    "          [ 1.6306e-01,  2.6444e-01, -3.9934e-01,  ...,  9.8310e-01,\n",
    "            2.7384e-01,  2.8581e-01],\n",
    "          [-4.1729e-01, -2.9284e-01, -5.9255e-01,  ...,  9.7331e-01,\n",
    "            2.4195e-01,  1.2344e-01],\n",
    "          [-1.2399e-01, -8.0821e-01, -1.0571e+00,  ..., -1.2115e-01,\n",
    "           -2.8900e-01, -6.3112e-01]]],\n",
    "\n",
    "\n",
    "        ...,\n",
    "\n",
    "\n",
    "        [[[ 5.9126e-01,  5.2255e-01,  3.8745e-01,  ...,  5.7286e-01,\n",
    "            4.3194e-01,  3.5242e-01],\n",
    "          [ 3.1973e-01,  3.6186e-01,  3.0231e-01,  ...,  4.1980e-01,\n",
    "            2.2392e-01,  1.3071e-01],\n",
    "          [ 3.5606e-01,  2.2316e-01,  1.7725e-01,  ...,  2.8293e-01,\n",
    "            1.9199e-01,  2.4361e-01],\n",
    "          ...,\n",
    "          [ 4.9236e-01,  6.7848e-01,  8.5653e-01,  ...,  6.4029e-01,\n",
    "            3.2186e-01,  2.9161e-01],\n",
    "          [ 6.3458e-01,  6.5724e-01,  7.9130e-01,  ...,  7.4824e-01,\n",
    "            5.0765e-01,  5.1354e-01],\n",
    "          [ 4.6136e-01,  5.0005e-01,  7.2711e-01,  ...,  8.6676e-01,\n",
    "            8.3441e-01,  8.3560e-01]],\n",
    "\n",
    "         [[ 3.9065e-02, -1.4328e-02,  3.1851e-02,  ..., -4.4492e-01,\n",
    "           -1.0419e-01, -8.1729e-02],\n",
    "          [-5.4154e-01, -4.3025e-01, -2.7938e-01,  ..., -5.4805e-02,\n",
    "           -1.1540e-01,  5.7576e-02],\n",
    "          [-6.3251e-01, -6.0171e-01, -3.8461e-01,  ...,  3.9839e-01,\n",
    "            4.3254e-01,  3.9645e-01],\n",
    "          ...,\n",
    "          [-3.6898e-01, -3.1478e-01, -2.7657e-01,  ...,  3.8080e-01,\n",
    "            5.5721e-01,  3.7581e-01],\n",
    "          [ 1.3063e-01, -1.3274e-02, -1.2220e-02,  ...,  5.0103e-01,\n",
    "            6.9311e-01,  5.1996e-01],\n",
    "          [ 2.1864e-01,  2.9771e-01,  5.8733e-01,  ...,  6.7839e-01,\n",
    "            5.7658e-01,  3.6567e-01]],\n",
    "\n",
    "         [[-2.3525e-01, -2.1730e-01, -2.7656e-01,  ..., -2.3401e-01,\n",
    "           -2.1782e-01, -2.8417e-01],\n",
    "          [-7.9790e-02, -6.1212e-03,  4.8462e-02,  ...,  2.9127e-02,\n",
    "            5.4246e-02,  9.8760e-02],\n",
    "          [ 7.1834e-02,  5.3098e-02, -3.9264e-02,  ...,  6.2874e-02,\n",
    "            1.3806e-01,  1.2626e-01],\n",
    "          ...,\n",
    "          [ 2.1461e-01,  1.8524e-01, -1.9998e-02,  ...,  3.3436e-02,\n",
    "            2.5826e-02, -6.5719e-02],\n",
    "          [-5.3718e-03, -1.9135e-01, -1.8648e-01,  ...,  2.2913e-01,\n",
    "            2.2794e-01,  1.9488e-01],\n",
    "          [-1.2101e-01, -1.5529e-01,  1.6307e-03,  ...,  3.6291e-01,\n",
    "            3.3798e-01,  3.0743e-01]],\n",
    "\n",
    "         ...,\n",
    "\n",
    "         [[-8.1027e-01, -7.4227e-01, -6.7911e-01,  ..., -8.7757e-01,\n",
    "           -9.6195e-01, -1.0344e+00],\n",
    "          [-6.9770e-01, -5.0862e-01, -5.5046e-01,  ..., -5.9522e-01,\n",
    "           -4.8302e-01, -5.0836e-01],\n",
    "          [-5.7719e-01, -6.3719e-01, -6.5549e-01,  ...,  1.7029e-02,\n",
    "            2.3537e-01,  9.8840e-02],\n",
    "          ...,\n",
    "          [-1.6682e-01, -2.7281e-01, -2.1969e-01,  ...,  2.9251e-01,\n",
    "            3.4106e-01,  4.2557e-01],\n",
    "          [-1.4629e-01, -1.5801e-01, -1.8220e-02,  ...,  2.7669e-01,\n",
    "            3.7766e-01,  4.2291e-01],\n",
    "          [ 6.9353e-02, -8.2793e-02,  8.1121e-02,  ...,  6.9465e-01,\n",
    "            8.4715e-01,  7.8515e-01]],\n",
    "\n",
    "         [[-2.6497e-02, -2.2681e-02,  7.6935e-02,  ...,  4.0366e-03,\n",
    "           -4.0708e-02, -5.7368e-02],\n",
    "          [ 3.5010e-03, -2.5279e-02,  2.3274e-01,  ..., -5.1529e-01,\n",
    "           -8.1330e-01, -8.1317e-01],\n",
    "          [-8.4762e-02, -1.1331e-01, -1.8556e-02,  ..., -6.7680e-01,\n",
    "           -8.1948e-01, -9.7827e-01],\n",
    "          ...,\n",
    "          [ 2.6618e-02, -1.3787e-01, -1.6782e-01,  ..., -1.0593e-01,\n",
    "            3.8690e-02,  1.1101e-01],\n",
    "          [ 1.8315e-02, -7.3656e-02, -1.0724e-01,  ..., -8.8266e-02,\n",
    "           -1.2043e-01, -5.1095e-02],\n",
    "          [ 4.8281e-02, -2.5691e-02, -5.7901e-02,  ..., -1.9166e-02,\n",
    "           -3.1593e-02,  9.0671e-02]],\n",
    "\n",
    "         [[ 3.1002e-01,  2.1810e-01, -4.8244e-03,  ...,  4.6810e-01,\n",
    "            1.1413e+00,  1.1178e+00],\n",
    "          [ 2.7234e-03,  3.2045e-01,  7.4915e-01,  ...,  1.7217e+00,\n",
    "            1.1133e+00,  3.6194e-01],\n",
    "          [ 1.0496e+00,  1.2702e+00,  1.3359e+00,  ...,  4.3706e-01,\n",
    "            8.5401e-01,  9.6063e-01],\n",
    "          ...,\n",
    "          [ 1.0267e-01,  1.5674e-01, -7.7420e-01,  ..., -2.8213e-01,\n",
    "           -4.0929e-02, -1.4281e-01],\n",
    "          [-3.5922e-02, -5.8154e-01, -8.7359e-01,  ...,  6.8092e-02,\n",
    "            6.1906e-01,  8.7230e-01],\n",
    "          [ 4.1053e-01,  2.8288e-01, -5.4740e-02,  ...,  1.0639e-01,\n",
    "            8.2902e-01,  1.0684e+00]]],\n",
    "\n",
    "\n",
    "        [[[ 6.1465e-01,  6.5009e-01,  3.4532e-01,  ...,  2.8632e-01,\n",
    "            2.2154e-01,  2.6062e-01],\n",
    "          [ 6.0129e-01,  5.0518e-01,  4.0719e-01,  ...,  3.3587e-01,\n",
    "            3.0785e-01,  1.8663e-01],\n",
    "          [ 5.5359e-01,  4.5998e-01,  3.5450e-01,  ...,  4.0653e-01,\n",
    "            4.4409e-01,  3.5481e-01],\n",
    "          ...,\n",
    "          [ 4.1861e-01,  3.8258e-01,  5.2327e-01,  ...,  4.4180e-01,\n",
    "            4.0826e-01,  7.5766e-01],\n",
    "          [ 5.5835e-01,  5.7161e-01,  7.8743e-01,  ...,  5.3659e-01,\n",
    "            5.1707e-01,  8.5805e-01],\n",
    "          [ 5.2857e-01,  5.8106e-01,  6.8307e-01,  ...,  6.4407e-01,\n",
    "            6.2619e-01,  7.6717e-01]],\n",
    "\n",
    "         [[-4.5680e-01, -4.4269e-01, -4.0493e-01,  ..., -6.2678e-01,\n",
    "           -6.8640e-01, -2.7372e-01],\n",
    "          [-7.0240e-01, -6.4063e-01, -5.7379e-01,  ..., -5.3389e-01,\n",
    "           -4.9955e-01, -3.3607e-01],\n",
    "          [-6.6995e-01, -4.5425e-01, -7.8650e-01,  ..., -3.1743e-01,\n",
    "           -4.7022e-01, -3.4731e-01],\n",
    "          ...,\n",
    "          [-6.0777e-01,  8.3874e-02, -2.6587e-01,  ..., -1.9917e-01,\n",
    "           -4.8605e-01, -2.8123e-01],\n",
    "          [-4.8039e-01, -1.3936e-01, -3.2644e-01,  ..., -1.9464e-01,\n",
    "           -2.1438e-01, -7.6532e-02],\n",
    "          [-1.6585e-01, -1.9210e-01, -4.0013e-01,  ..., -1.6300e-01,\n",
    "            3.2003e-02,  1.5892e-02]],\n",
    "\n",
    "         [[-1.2367e-01, -2.2165e-01, -2.0223e-01,  ..., -2.7798e-01,\n",
    "           -1.6785e-01,  3.0958e-02],\n",
    "          [-1.6460e-01, -2.9143e-01, -1.0756e-01,  ...,  4.5941e-03,\n",
    "            6.2442e-02, -3.7008e-02],\n",
    "          [-3.5836e-01, -4.6158e-01, -2.0455e-01,  ...,  1.0692e-02,\n",
    "            1.4474e-02, -1.4604e-02],\n",
    "          ...,\n",
    "          [-4.3820e-02,  2.1466e-01,  2.4725e-02,  ...,  1.1426e-01,\n",
    "            1.4711e-01,  8.3797e-02],\n",
    "          [-1.9677e-01, -1.8641e-01, -2.6716e-01,  ...,  2.3945e-01,\n",
    "            2.3121e-01,  3.7571e-03],\n",
    "          [ 4.1439e-02, -4.8724e-03,  3.3334e-02,  ...,  2.5751e-02,\n",
    "           -8.0574e-03, -1.8382e-01]],\n",
    "\n",
    "         ...,\n",
    "\n",
    "         [[ 2.1329e-01, -5.9653e-02, -1.5604e-01,  ..., -7.1488e-01,\n",
    "           -7.6387e-01, -5.9798e-01],\n",
    "          [-8.0330e-02,  2.2398e-02, -5.8194e-02,  ..., -3.0828e-01,\n",
    "           -5.0003e-01, -6.0357e-01],\n",
    "          [-5.3255e-01, -3.3418e-01, -1.7544e-01,  ..., -2.9902e-01,\n",
    "           -4.1461e-01, -2.3507e-01],\n",
    "          ...,\n",
    "          [-1.8249e-01, -5.3304e-01, -1.7085e-01,  ..., -4.6409e-01,\n",
    "           -3.0948e-01, -1.6093e-01],\n",
    "          [-2.2847e-01, -1.7919e-01,  5.3718e-02,  ..., -4.7066e-01,\n",
    "           -3.1612e-01, -1.7645e-01],\n",
    "          [-4.3638e-02,  7.6460e-03, -1.2091e-01,  ..., -3.3396e-01,\n",
    "           -2.6347e-01,  4.8298e-02]],\n",
    "\n",
    "         [[ 1.4541e-01,  2.7424e-01,  3.4410e-01,  ...,  2.8117e-02,\n",
    "           -3.3711e-04, -2.0794e-02],\n",
    "          [ 3.1095e-01,  1.5535e-01,  4.6833e-01,  ...,  1.9561e-01,\n",
    "            1.2882e-02, -1.2975e-01],\n",
    "          [ 1.8451e-01,  2.4812e-01,  2.7674e-01,  ...,  4.8307e-01,\n",
    "            2.0428e-01, -1.1342e-01],\n",
    "          ...,\n",
    "          [ 2.3386e-01,  2.9862e-01,  1.1453e-01,  ...,  4.3215e-01,\n",
    "            9.3062e-02, -1.7536e-01],\n",
    "          [ 1.6735e-01,  2.0432e-01, -1.3752e-01,  ...,  2.8099e-01,\n",
    "            1.3363e-01, -9.7912e-02],\n",
    "          [ 1.3491e-01,  1.7925e-01, -1.2360e-01,  ..., -3.1425e-02,\n",
    "           -2.4431e-02, -8.6346e-02]],\n",
    "\n",
    "         [[ 1.1106e-01,  1.0402e+00,  9.5398e-01,  ...,  1.1806e-01,\n",
    "            5.5384e-01,  1.2382e+00],\n",
    "          [ 2.8158e-01,  9.3339e-01,  9.0357e-01,  ...,  9.0371e-01,\n",
    "            1.0496e+00,  1.2097e+00],\n",
    "          [-4.5530e-02,  2.4920e-01,  4.6825e-01,  ...,  1.1788e+00,\n",
    "            8.6613e-01,  3.6285e-01],\n",
    "          ...,\n",
    "          [-6.9583e-01,  4.2556e-01,  1.4392e+00,  ...,  1.9440e-01,\n",
    "           -6.3546e-02, -1.0780e+00],\n",
    "          [-3.6997e-01, -1.1695e+00,  4.2532e-01,  ...,  1.2033e-01,\n",
    "            3.6212e-01, -1.5877e-01],\n",
    "          [-7.5553e-02,  1.2381e-01, -1.3603e-01,  ..., -2.8189e-01,\n",
    "            8.8009e-02, -9.3924e-01]]],\n",
    "\n",
    "\n",
    "        [[[ 3.3698e-01,  3.2273e-01,  3.4482e-01,  ...,  3.4371e-01,\n",
    "            3.6141e-01,  2.8442e-01],\n",
    "          [ 4.6704e-01,  4.9731e-01,  4.7403e-01,  ...,  4.4529e-01,\n",
    "            4.4832e-01,  3.4806e-01],\n",
    "          [ 4.8194e-01,  4.8598e-01,  5.0562e-01,  ...,  4.4127e-01,\n",
    "            4.4185e-01,  4.1519e-01],\n",
    "          ...,\n",
    "          [ 3.3931e-01,  4.0589e-01,  4.9889e-01,  ...,  5.2579e-01,\n",
    "            6.4835e-01,  6.6735e-01],\n",
    "          [ 3.5633e-01,  4.8019e-01,  6.5669e-01,  ...,  7.4506e-01,\n",
    "            7.8759e-01,  7.8557e-01],\n",
    "          [ 3.8149e-01,  5.2184e-01,  6.5533e-01,  ...,  6.4862e-01,\n",
    "            6.6075e-01,  6.4976e-01]],\n",
    "\n",
    "         [[-5.2310e-01, -5.7432e-01, -5.0301e-01,  ..., -2.7834e-01,\n",
    "            1.1201e-01, -1.6056e-01],\n",
    "          [-5.2553e-01, -3.4451e-01, -4.1606e-01,  ..., -3.6321e-01,\n",
    "            1.3044e-01, -2.2210e-02],\n",
    "          [-5.0701e-01, -2.7857e-01, -1.5869e-01,  ...,  3.2241e-02,\n",
    "            7.5361e-01,  7.4649e-01],\n",
    "          ...,\n",
    "          [-1.9373e-01, -2.3277e-01, -1.8035e-01,  ...,  1.7386e-01,\n",
    "            8.8719e-01,  8.1363e-01],\n",
    "          [ 1.1620e-01,  2.0321e-02, -1.9846e-01,  ..., -1.8606e-01,\n",
    "            1.7704e-01,  7.9672e-02],\n",
    "          [ 1.1600e-01,  4.1854e-02, -2.3429e-01,  ..., -5.2628e-01,\n",
    "           -5.1069e-01, -5.2447e-01]],\n",
    "\n",
    "         [[-3.0675e-01, -2.4031e-01, -8.8967e-02,  ...,  1.4469e-01,\n",
    "            2.7144e-01, -1.3399e-02],\n",
    "          [-1.9406e-01, -2.1557e-01, -2.3016e-02,  ...,  1.9779e-01,\n",
    "            2.5030e-01,  1.2508e-01],\n",
    "          [-2.4912e-01, -1.5635e-01,  7.5502e-02,  ..., -3.2609e-02,\n",
    "            3.9762e-02, -4.0771e-02],\n",
    "          ...,\n",
    "          [ 4.4731e-03,  2.5321e-01, -1.7976e-01,  ..., -1.3803e-01,\n",
    "           -9.9954e-02, -1.9109e-01],\n",
    "          [ 3.1609e-01,  2.7247e-01, -2.1757e-01,  ..., -5.1407e-01,\n",
    "           -5.3128e-01, -6.6527e-01],\n",
    "          [ 2.0205e-01,  1.4341e-01, -6.0947e-02,  ..., -1.2523e-01,\n",
    "           -1.9184e-01, -2.3483e-01]],\n",
    "\n",
    "         ...,\n",
    "\n",
    "         [[ 1.6657e-01,  7.6250e-02, -6.8936e-02,  ..., -4.4001e-01,\n",
    "           -2.7780e-01, -1.3882e-01],\n",
    "          [ 3.3685e-01,  2.9091e-01,  5.5184e-02,  ..., -7.8383e-02,\n",
    "            1.9327e-03,  2.3809e-02],\n",
    "          [ 6.9297e-03, -7.3740e-02, -2.0046e-01,  ..., -1.4476e-02,\n",
    "            1.7110e-01,  2.8014e-01],\n",
    "          ...,\n",
    "          [ 2.2882e-01,  1.7528e-01,  3.7043e-01,  ...,  2.9996e-01,\n",
    "            5.9618e-01,  7.9117e-01],\n",
    "          [ 5.3167e-01,  5.9184e-01,  5.6182e-01,  ...,  5.7527e-01,\n",
    "            6.5202e-01,  7.4816e-01],\n",
    "          [ 4.8891e-01,  3.9149e-01,  3.6199e-01,  ...,  2.6510e-01,\n",
    "            2.9185e-01,  3.0159e-01]],\n",
    "\n",
    "         [[ 4.8012e-01,  4.3668e-01,  4.2252e-01,  ..., -8.7798e-02,\n",
    "           -5.7253e-01, -8.3742e-01],\n",
    "          [ 2.7140e-01,  5.1480e-01,  5.7858e-01,  ...,  1.2542e-01,\n",
    "            1.3741e-01,  3.0878e-01],\n",
    "          [-1.9117e-01,  1.0922e-01,  4.1108e-01,  ...,  1.7326e-01,\n",
    "           -2.5796e-02,  5.0400e-02],\n",
    "          ...,\n",
    "          [-5.0801e-01, -6.8187e-01, -5.1170e-01,  ..., -9.4546e-03,\n",
    "            2.8283e-02,  1.4312e-01],\n",
    "          [-2.1525e-01, -1.7962e-01, -1.2453e-01,  ..., -7.1468e-02,\n",
    "            5.8970e-02,  1.0240e-02],\n",
    "          [ 3.0244e-01,  3.5413e-01,  1.2624e-01,  ..., -2.1655e-02,\n",
    "            8.0486e-02,  7.6809e-02]],\n",
    "\n",
    "         [[ 9.6957e-01,  9.5145e-01,  7.8461e-01,  ...,  4.9642e-01,\n",
    "            3.4025e-01, -1.9265e-01],\n",
    "          [ 9.1728e-01,  5.2402e-01,  1.9246e-01,  ..., -1.2912e+00,\n",
    "           -8.7243e-01,  1.8609e-01],\n",
    "          [ 2.4995e-02, -4.5209e-01, -1.7064e-01,  ..., -8.4435e-01,\n",
    "           -4.8179e-01,  5.1439e-01],\n",
    "          ...,\n",
    "          [ 2.0517e-01, -7.0412e-01, -1.2152e+00,  ..., -8.5557e-01,\n",
    "            1.5857e-01,  7.1323e-01],\n",
    "          [ 1.1682e-03, -2.4260e-01, -6.5581e-01,  ..., -1.3990e+00,\n",
    "           -1.0847e+00, -4.2192e-01],\n",
    "          [ 1.7470e-01, -3.5703e-01, -4.2366e-01,  ...,  3.9531e-01,\n",
    "            5.3271e-01,  7.5155e-01]]]], device='cuda:0')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<InstanceData(\n",
    "\n",
    "    META INFORMATION\n",
    "    pad_shape: (992, 672)\n",
    "    img_id: 351235\n",
    "    normed_boxes: [[[tensor([[0., 0., 1., 1.]])], [tensor([[0.4737, 0.0000, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 0.5263, 1.0000]]), tensor([[0.0000, 0.0000, 0.5263, 1.0000],\n",
    "                [0.4737, 0.0000, 1.0000, 1.0000]])], [tensor([[0.6429, 0.4737, 1.0000, 1.0000],\n",
    "                [0.3214, 0.4737, 0.6786, 1.0000],\n",
    "                [0.0000, 0.0000, 0.3571, 0.5263]]), tensor([[0.0000, 0.0000, 0.3571, 0.5263],\n",
    "                [0.6429, 0.4737, 1.0000, 1.0000],\n",
    "                [0.3214, 0.4737, 0.6786, 1.0000]])]], [[tensor([[0.4737, 0.4737, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 0.5263, 0.5263],\n",
    "                [0.4737, 0.0000, 1.0000, 0.5263]]), tensor([[0.0000, 0.0000, 0.5263, 0.5263],\n",
    "                [0.4737, 0.4737, 1.0000, 1.0000],\n",
    "                [0.4737, 0.0000, 1.0000, 0.5263]])], [tensor([[0.0000, 0.4737, 0.4209, 1.0000],\n",
    "                [0.3566, 0.0000, 1.0000, 0.5263]]), tensor([[0.3566, 0.0000, 1.0000, 0.5263],\n",
    "                [0.0000, 0.4737, 0.4209, 1.0000]])], [tensor([[0.0000, 0.0000, 0.4209, 1.0000],\n",
    "                [0.3566, 0.0000, 1.0000, 1.0000]]), tensor([[0.3566, 0.0000, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 0.4209, 1.0000]])]], [[tensor([[0.0000, 0.0000, 0.3868, 1.0000],\n",
    "                [0.6962, 0.0000, 1.0000, 1.0000],\n",
    "                [0.3481, 0.0000, 0.7349, 1.0000]]), tensor([[0.6962, 0.0000, 1.0000, 1.0000],\n",
    "                [0.3481, 0.0000, 0.7349, 1.0000],\n",
    "                [0.0000, 0.0000, 0.3868, 1.0000]])], [tensor([[0.0000, 0.0000, 0.5933, 1.0000],\n",
    "                [0.5340, 0.0000, 1.0000, 1.0000]]), tensor([[0.5340, 0.0000, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 0.5933, 1.0000]])], [tensor([[0., 0., 1., 1.]])]], [[tensor([[0., 0., 1., 1.]])], [tensor([[0.4737, 0.0000, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 0.5263, 1.0000]]), tensor([[0.0000, 0.0000, 0.5263, 1.0000],\n",
    "                [0.4737, 0.0000, 1.0000, 1.0000]])], [tensor([[0.0000, 0.0000, 0.5263, 0.7330],\n",
    "                [0.4737, 0.6597, 1.0000, 1.0000]]), tensor([[0.4737, 0.6597, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 0.5263, 0.7330]])]], [[tensor([[0.4737, 0.0000, 1.0000, 0.5263],\n",
    "                [0.4737, 0.4737, 1.0000, 1.0000],\n",
    "                [0.0000, 0.4737, 0.5263, 1.0000]]), tensor([[0.4737, 0.4737, 1.0000, 1.0000],\n",
    "                [0.4737, 0.0000, 1.0000, 0.5263],\n",
    "                [0.0000, 0.4737, 0.5263, 1.0000]])], [tensor([[0.0000, 0.0000, 0.5263, 0.5263],\n",
    "                [0.4737, 0.0000, 1.0000, 0.5263],\n",
    "                [0.0000, 0.4737, 0.5263, 1.0000]]), tensor([[0.0000, 0.4737, 0.5263, 1.0000],\n",
    "                [0.4737, 0.0000, 1.0000, 0.5263],\n",
    "                [0.0000, 0.0000, 0.5263, 0.5263]])], [tensor([[0.0000, 0.6429, 0.5263, 1.0000],\n",
    "                [0.4737, 0.3214, 1.0000, 0.6786],\n",
    "                [0.4737, 0.0000, 1.0000, 0.3571]]), tensor([[0.4737, 0.3214, 1.0000, 0.6786],\n",
    "                [0.0000, 0.6429, 0.5263, 1.0000],\n",
    "                [0.4737, 0.0000, 1.0000, 0.3571]])]]]\n",
    "    batch_input_shape: (992, 672)\n",
    "    spanned_boxes: [[tensor([184.5790, 317.7891, 317.2724, 566.5359]), tensor([ 65.1550, 317.7891, 317.2724, 566.5359]), tensor([ 65.1550,  93.9169, 436.6964, 566.5359])], [tensor([ 54.7809, 286.5738, 242.5951, 628.7074]), tensor([  0.0000, 286.5738, 153.6305, 628.7074]), tensor([  0.0000, 286.5738, 153.6305, 466.6441])], [tensor([388.8122, 361.1613, 672.0000, 619.5211]), tensor([487.3905, 361.1613, 672.0000, 619.5211]), tensor([487.3905, 361.1613, 596.9219, 619.5211])], [tensor([ 86.2324, 690.3457, 139.5657, 898.9957]), tensor([ 86.2324, 690.3457, 187.5657, 898.9957]), tensor([ 86.2324, 690.3457, 187.5657, 975.0000])], [tensor([ 26.9638, 627.0926, 219.9314, 761.1094]), tensor([118.3695, 690.5742, 311.3371, 824.5910]), tensor([ 26.9638, 627.0926, 219.9314, 824.5910])]]\n",
    "    img_path: '/work/ovdet/data/coco/train2017/000000351235.jpg'\n",
    "    flip: True\n",
    "    img_shape: (975, 672)\n",
    "    ori_shape: (640, 441)\n",
    "    scale_factor: (1.5238095238095237, 1.5234375)\n",
    "    box_ids: [[[4], [4, 3], [3, 4], [5, 4, 0], [0, 5, 4]], [[8, 4, 5], [4, 8, 5], [6, 4], [4, 6], [3, 4], [4, 3]], [[3, 5, 4], [5, 4, 3], [4, 5], [5, 4], [4]], [[4], [5, 4], [4, 5], [4, 8], [8, 4]], [[1, 4, 3], [4, 1, 3], [4, 5, 7], [7, 5, 4], [6, 4, 1], [4, 6, 1]]]\n",
    "    flip_direction: 'horizontal'\n",
    "\n",
    "    DATA FIELDS\n",
    "    bboxes: tensor([[184.5790, 317.7891, 317.2724, 566.5359],\n",
    "                [184.5790, 317.7891, 317.2724, 566.5359],\n",
    "                [ 65.1550, 317.7891, 197.8484, 566.5359],\n",
    "                [ 65.1550, 317.7891, 197.8484, 566.5359],\n",
    "                [184.5790, 317.7891, 317.2724, 566.5359],\n",
    "                [304.0031, 317.7891, 436.6964, 566.5359],\n",
    "                [184.5790, 317.7891, 317.2724, 566.5359],\n",
    "                [ 65.1550,  93.9169, 197.8484, 342.6638],\n",
    "                [ 65.1550,  93.9169, 197.8484, 342.6638],\n",
    "                [304.0031, 317.7891, 436.6964, 566.5359],\n",
    "                [184.5790, 317.7891, 317.2724, 566.5359],\n",
    "                [143.7455, 448.6371, 242.5951, 628.7074],\n",
    "                [ 54.7809, 286.5738, 153.6305, 466.6441],\n",
    "                [143.7455, 286.5738, 242.5951, 466.6441],\n",
    "                [ 54.7809, 286.5738, 153.6305, 466.6441],\n",
    "                [143.7455, 448.6371, 242.5951, 628.7074],\n",
    "                [143.7455, 286.5738, 242.5951, 466.6441],\n",
    "                [  0.0000, 448.6371,  64.6659, 628.7074],\n",
    "                [ 54.7809, 286.5738, 153.6305, 466.6441],\n",
    "                [ 54.7809, 286.5738, 153.6305, 466.6441],\n",
    "                [  0.0000, 448.6371,  64.6659, 628.7074],\n",
    "                [  0.0000, 286.5738,  64.6659, 466.6441],\n",
    "                [ 54.7809, 286.5738, 153.6305, 466.6441],\n",
    "                [ 54.7809, 286.5738, 153.6305, 466.6441],\n",
    "                [  0.0000, 286.5738,  64.6659, 466.6441],\n",
    "                [388.8122, 361.1613, 498.3436, 619.5211],\n",
    "                [585.9688, 361.1613, 672.0000, 619.5211],\n",
    "                [487.3905, 361.1613, 596.9219, 619.5211],\n",
    "                [585.9688, 361.1613, 672.0000, 619.5211],\n",
    "                [487.3905, 361.1613, 596.9219, 619.5211],\n",
    "                [388.8122, 361.1613, 498.3436, 619.5211],\n",
    "                [487.3905, 361.1613, 596.9219, 619.5211],\n",
    "                [585.9688, 361.1613, 672.0000, 619.5211],\n",
    "                [585.9688, 361.1613, 672.0000, 619.5211],\n",
    "                [487.3905, 361.1613, 596.9219, 619.5211],\n",
    "                [487.3905, 361.1613, 596.9219, 619.5211],\n",
    "                [ 86.2324, 690.3457, 139.5657, 898.9957],\n",
    "                [134.2323, 690.3457, 187.5657, 898.9957],\n",
    "                [ 86.2324, 690.3457, 139.5657, 898.9957],\n",
    "                [ 86.2324, 690.3457, 139.5657, 898.9957],\n",
    "                [134.2323, 690.3457, 187.5657, 898.9957],\n",
    "                [ 86.2324, 690.3457, 139.5657, 898.9957],\n",
    "                [134.2323, 878.1307, 187.5657, 975.0000],\n",
    "                [134.2323, 878.1307, 187.5657, 975.0000],\n",
    "                [ 86.2324, 690.3457, 139.5657, 898.9957],\n",
    "                [118.3695, 627.0926, 219.9314, 697.6277],\n",
    "                [118.3695, 690.5742, 219.9314, 761.1094],\n",
    "                [ 26.9638, 690.5742, 128.5257, 761.1094],\n",
    "                [118.3695, 690.5742, 219.9314, 761.1094],\n",
    "                [118.3695, 627.0926, 219.9314, 697.6277],\n",
    "                [ 26.9638, 690.5742, 128.5257, 761.1094],\n",
    "                [118.3695, 690.5742, 219.9314, 761.1094],\n",
    "                [209.7752, 690.5742, 311.3371, 761.1094],\n",
    "                [118.3695, 754.0558, 219.9314, 824.5910],\n",
    "                [118.3695, 754.0558, 219.9314, 824.5910],\n",
    "                [209.7752, 690.5742, 311.3371, 761.1094],\n",
    "                [118.3695, 690.5742, 219.9314, 761.1094],\n",
    "                [ 26.9638, 754.0558, 128.5257, 824.5910],\n",
    "                [118.3695, 690.5742, 219.9314, 761.1094],\n",
    "                [118.3695, 627.0926, 219.9314, 697.6277],\n",
    "                [118.3695, 690.5742, 219.9314, 761.1094],\n",
    "                [ 26.9638, 754.0558, 128.5257, 824.5910],\n",
    "                [118.3695, 627.0926, 219.9314, 697.6277]], device='cuda:0')\n",
    ") at 0x7fd0adf7e690>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epeated crops = torch.tensor([[[[-0.1957, -0.2267, -0.2497,  ..., -1.2515, -1.2494, -1.2584],\n",
    "          [-0.1482, -0.1769, -0.2000,  ..., -1.2504, -1.2445, -1.2528],\n",
    "          [-0.0936, -0.1201, -0ㅠㅠㅠ.1432,  ..., -1.2528, -1.2432, -1.2492],\n",
    "          ...,\n",
    "          [-0.1656, -0.1656, -0.1656,  ..., -1.3194, -1.3395, -1.3552],\n",
    "          [-0.1529, -0.1529, -0.1529,  ..., -1.3082, -1.3290, -1.3464],\n",
    "          [-0.1458, -0.1458, -0.1458,  ..., -1.2929, -1.3099, -1.3281]],\n",
    "\n",
    "         [[-0.0507, -0.0834, -0.1093,  ..., -1.3721, -1.3563, -1.3556],\n",
    "          [-0.0019, -0.0339, -0.0636,  ..., -1.3721, -1.3563, -1.3541],\n",
    "          [ 0.0495,  0.0209, -0.0088,  ..., -1.3752, -1.3574, -1.3533],\n",
    "          ...,\n",
    "          [-0.1182, -0.1226, -0.1241,  ..., -1.4243, -1.4322, -1.4433],\n",
    "          [-0.1129, -0.1163, -0.1163,  ..., -1.4199, -1.4278, -1.4389],\n",
    "          [-0.1152, -0.1163, -0.1163,  ..., -1.4126, -1.4205, -1.4316]],\n",
    "\n",
    "         [[-0.1519, -0.1896, -0.2196,  ..., -1.0000, -0.9979, -1.0089],\n",
    "          [-0.1125, -0.1481, -0.1780,  ..., -1.0058, -1.0001, -1.0089],\n",
    "          [-0.0685, -0.0989, -0.1271,  ..., -1.0121, -1.0046, -1.0116],\n",
    "          ...,\n",
    "          [ 0.2350,  0.2350,  0.2350,  ..., -1.0417, -1.0492, -1.0597],\n",
    "          [ 0.2446,  0.2446,  0.2446,  ..., -1.0340, -1.0437, -1.0555],\n",
    "          [ 0.2515,  0.2515,  0.2515,  ..., -1.0212, -1.0346, -1.0486]]],\n",
    "\n",
    "\n",
    "        [[[-0.1957, -0.2267, -0.2497,  ..., -1.2515, -1.2494, -1.2584],\n",
    "          [-0.1482, -0.1769, -0.2000,  ..., -1.2504, -1.2445, -1.2528],\n",
    "          [-0.0936, -0.1201, -0.1432,  ..., -1.2528, -1.2432, -1.2492],\n",
    "          ...,\n",
    "          [-0.1656, -0.1656, -0.1656,  ..., -1.3194, -1.3395, -1.3552],\n",
    "          [-0.1529, -0.1529, -0.1529,  ..., -1.3082, -1.3290, -1.3464],\n",
    "          [-0.1458, -0.1458, -0.1458,  ..., -1.2929, -1.3099, -1.3281]],\n",
    "\n",
    "         [[-0.0507, -0.0834, -0.1093,  ..., -1.3721, -1.3563, -1.3556],\n",
    "          [-0.0019, -0.0339, -0.0636,  ..., -1.3721, -1.3563, -1.3541],\n",
    "          [ 0.0495,  0.0209, -0.0088,  ..., -1.3752, -1.3574, -1.3533],\n",
    "          ...,\n",
    "          [-0.1182, -0.1226, -0.1241,  ..., -1.4243, -1.4322, -1.4433],\n",
    "          [-0.1129, -0.1163, -0.1163,  ..., -1.4199, -1.4278, -1.4389],\n",
    "          [-0.1152, -0.1163, -0.1163,  ..., -1.4126, -1.4205, -1.4316]],\n",
    "\n",
    "         [[-0.1519, -0.1896, -0.2196,  ..., -1.0000, -0.9979, -1.0089],\n",
    "          [-0.1125, -0.1481, -0.1780,  ..., -1.0058, -1.0001, -1.0089],\n",
    "          [-0.0685, -0.0989, -0.1271,  ..., -1.0121, -1.0046, -1.0116],\n",
    "          ...,\n",
    "          [ 0.2350,  0.2350,  0.2350,  ..., -1.0417, -1.0492, -1.0597],\n",
    "          [ 0.2446,  0.2446,  0.2446,  ..., -1.0340, -1.0437, -1.0555],\n",
    "          [ 0.2515,  0.2515,  0.2515,  ..., -1.0212, -1.0346, -1.0486]]],\n",
    "\n",
    "\n",
    "        [[[-0.1062, -0.1215, -0.1253,  ..., -1.3416, -1.3117, -1.2907],\n",
    "          [-0.1202, -0.1360, -0.1437,  ..., -1.3236, -1.3032, -1.2885],\n",
    "          [-0.1274, -0.1459, -0.1588,  ..., -1.3122, -1.3226, -1.3297],\n",
    "          ...,\n",
    "          [-1.2864, -1.2929, -1.3003,  ..., -1.3638, -1.3808, -1.3946],\n",
    "          [-1.3290, -1.3380, -1.3344,  ..., -1.3796, -1.4001, -1.4134],\n",
    "          [-1.3466, -1.3498, -1.3319,  ..., -1.3951, -1.4080, -1.4163]],\n",
    "\n",
    "         [[ 0.0328,  0.0269,  0.0269,  ..., -1.4546, -1.4276, -1.4089],\n",
    "          [-0.0027, -0.0094, -0.0127,  ..., -1.4430, -1.4297, -1.4205],\n",
    "          [-0.0284, -0.0390, -0.0496,  ..., -1.4350, -1.4534, -1.4659],\n",
    "          ...,\n",
    "          [-1.3509, -1.3568, -1.3565,  ..., -1.4651, -1.4806, -1.4934],\n",
    "          [-1.3959, -1.4032, -1.3915,  ..., -1.4879, -1.5033, -1.5142],\n",
    "          [-1.4140, -1.4166, -1.3955,  ..., -1.5084, -1.5191, -1.5263]],\n",
    "\n",
    "         [[ 0.0112, -0.0112, -0.0225,  ..., -1.0940, -1.0790, -1.0688],\n",
    "          [ 0.0127, -0.0132, -0.0268,  ..., -1.0891, -1.0803, -1.0737],\n",
    "          [ 0.0335,  0.0067, -0.0183,  ..., -1.0852, -1.1024, -1.1150],\n",
    "          ...,\n",
    "          [-0.9531, -0.9655, -0.9742,  ..., -1.0946, -1.1094, -1.1216],\n",
    "          [-0.9844, -0.9988, -0.9953,  ..., -1.1172, -1.1371, -1.1487],\n",
    "          [-0.9885, -0.9984, -0.9859,  ..., -1.1363, -1.1486, -1.1548]]],\n",
    "\n",
    "\n",
    "        [[[-0.1062, -0.1215, -0.1253,  ..., -1.3416, -1.3117, -1.2907],\n",
    "          [-0.1202, -0.1360, -0.1437,  ..., -1.3236, -1.3032, -1.2885],\n",
    "          [-0.1274, -0.1459, -0.1588,  ..., -1.3122, -1.3226, -1.3297],\n",
    "          ...,\n",
    "          [-1.2864, -1.2929, -1.3003,  ..., -1.3638, -1.3808, -1.3946],\n",
    "          [-1.3290, -1.3380, -1.3344,  ..., -1.3796, -1.4001, -1.4134],\n",
    "          [-1.3466, -1.3498, -1.3319,  ..., -1.3951, -1.4080, -1.4163]],\n",
    "\n",
    "         [[ 0.0328,  0.0269,  0.0269,  ..., -1.4546, -1.4276, -1.4089],\n",
    "          [-0.0027, -0.0094, -0.0127,  ..., -1.4430, -1.4297, -1.4205],\n",
    "          [-0.0284, -0.0390, -0.0496,  ..., -1.4350, -1.4534, -1.4659],\n",
    "          ...,\n",
    "          [-1.3509, -1.3568, -1.3565,  ..., -1.4651, -1.4806, -1.4934],\n",
    "          [-1.3959, -1.4032, -1.3915,  ..., -1.4879, -1.5033, -1.5142],\n",
    "          [-1.4140, -1.4166, -1.3955,  ..., -1.5084, -1.5191, -1.5263]],\n",
    "\n",
    "         [[ 0.0112, -0.0112, -0.0225,  ..., -1.0940, -1.0790, -1.0688],\n",
    "          [ 0.0127, -0.0132, -0.0268,  ..., -1.0891, -1.0803, -1.0737],\n",
    "          [ 0.0335,  0.0067, -0.0183,  ..., -1.0852, -1.1024, -1.1150],\n",
    "          ...,\n",
    "          [-0.9531, -0.9655, -0.9742,  ..., -1.0946, -1.1094, -1.1216],\n",
    "          [-0.9844, -0.9988, -0.9953,  ..., -1.1172, -1.1371, -1.1487],\n",
    "          [-0.9885, -0.9984, -0.9859,  ..., -1.1363, -1.1486, -1.1548]]],\n",
    "\n",
    "\n",
    "        [[[-0.1824, -0.2207, -0.2359,  ..., -1.3592, -1.3336, -1.2957],\n",
    "          [-0.0785, -0.1142, -0.1441,  ..., -1.3323, -1.3183, -1.2919],\n",
    "          [ 0.0266, -0.0075, -0.0504,  ..., -1.3025, -1.3151, -1.3280],\n",
    "          ...,\n",
    "          [-1.2139, -1.2049, -1.2108,  ..., -1.3453, -1.3686, -1.3914],\n",
    "          [-1.2239, -1.2105, -1.2151,  ..., -1.3658, -1.3851, -1.4103],\n",
    "          [-1.2363, -1.2240, -1.2286,  ..., -1.3800, -1.3989, -1.4144]],\n",
    "\n",
    "         [[-0.0371, -0.0807, -0.1022,  ..., -1.4720, -1.4474, -1.4133],\n",
    "          [ 0.0623,  0.0217, -0.0127,  ..., -1.4472, -1.4396, -1.4226],\n",
    "          [ 0.1659,  0.1328,  0.0869,  ..., -1.4182, -1.4401, -1.4630],\n",
    "          ...,\n",
    "          [-1.2233, -1.2186, -1.2294,  ..., -1.4525, -1.4693, -1.4904],\n",
    "          [-1.2397, -1.2274, -1.2338,  ..., -1.4770, -1.4921, -1.5116],\n",
    "          [-1.2575, -1.2429, -1.2477,  ..., -1.4933, -1.5116, -1.5246]],\n",
    "\n",
    "         [[-0.1439, -0.1922, -0.2155,  ..., -1.1118, -1.0897, -1.0712],\n",
    "          [-0.0580, -0.0981, -0.1308,  ..., -1.0995, -1.0865, -1.0753],\n",
    "          [ 0.0328,  0.0024, -0.0394,  ..., -1.0742, -1.0899, -1.1120],\n",
    "          ...,\n",
    "          [-0.8915, -0.8881, -0.8944,  ..., -1.0842, -1.0986, -1.1187],\n",
    "          [-0.9094, -0.8978, -0.8986,  ..., -1.1058, -1.1225, -1.1460],\n",
    "          [-0.9262, -0.9125, -0.9118,  ..., -1.1264, -1.1397, -1.1533]]],\n",
    "\n",
    "\n",
    "        [[[-0.1824, -0.2207, -0.2359,  ..., -1.3592, -1.3336, -1.2957],\n",
    "          [-0.0785, -0.1142, -0.1441,  ..., -1.3323, -1.3183, -1.2919],\n",
    "          [ 0.0266, -0.0075, -0.0504,  ..., -1.3025, -1.3151, -1.3280],\n",
    "          ...,\n",
    "          [-1.2139, -1.2049, -1.2108,  ..., -1.3453, -1.3686, -1.3914],\n",
    "          [-1.2239, -1.2105, -1.2151,  ..., -1.3658, -1.3851, -1.4103],\n",
    "          [-1.2363, -1.2240, -1.2286,  ..., -1.3800, -1.3989, -1.4144]],\n",
    "\n",
    "         [[-0.0371, -0.0807, -0.1022,  ..., -1.4720, -1.4474, -1.4133],\n",
    "          [ 0.0623,  0.0217, -0.0127,  ..., -1.4472, -1.4396, -1.4226],\n",
    "          [ 0.1659,  0.1328,  0.0869,  ..., -1.4182, -1.4401, -1.4630],\n",
    "          ...,\n",
    "          [-1.2233, -1.2186, -1.2294,  ..., -1.4525, -1.4693, -1.4904],\n",
    "          [-1.2397, -1.2274, -1.2338,  ..., -1.4770, -1.4921, -1.5116],\n",
    "          [-1.2575, -1.2429, -1.2477,  ..., -1.4933, -1.5116, -1.5246]],\n",
    "\n",
    "         [[-0.1439, -0.1922, -0.2155,  ..., -1.1118, -1.0897, -1.0712],\n",
    "          [-0.0580, -0.0981, -0.1308,  ..., -1.0995, -1.0865, -1.0753],\n",
    "          [ 0.0328,  0.0024, -0.0394,  ..., -1.0742, -1.0899, -1.1120],\n",
    "          ...,\n",
    "          [-0.8915, -0.8881, -0.8944,  ..., -1.0842, -1.0986, -1.1187],\n",
    "          [-0.9094, -0.8978, -0.8986,  ..., -1.1058, -1.1225, -1.1460],\n",
    "          [-0.9262, -0.9125, -0.9118,  ..., -1.1264, -1.1397, -1.1533]]]],\n",
    "       device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23개의 이미지가 saved_images 디렉토리에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def save_tensor_images(tensor, save_dir='saved_images'):\n",
    "    # 저장할 디렉토리 생성\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    # 텐서가 [batch_size, channels, height, width] 형태인지 확인\n",
    "    assert tensor.ndim == 4 and tensor.size(1) == 3, \"입력 텐서는 [batch_size, 3, height, width] 형식이어야 합니다.\"\n",
    "    \n",
    "    batch_size = tensor.size(0)\n",
    "\n",
    "    sav_dir = \"/work/ovdet/work_dirs/jh/test_batch_img\"\n",
    "    for img in range(repeated_crops.shape[0]):\n",
    "        img = img.permute(1, 2, 0).cpu().numpy()\n",
    "        img = (img - img.min()) / (img.max() - img.min())  # 이미지 정규화\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')  # 축 제거\n",
    "        file_path = os.path.join(save_dir, f'image_{i+1}.png')  # 파일 이름 설정\n",
    "        plt.savefig(file_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()  # 메모리 해제를 위해 close\n",
    "        \n",
    "    for i in range(batch_size):\n",
    "        # [3, 224, 224] 텐서를 [224, 224, 3]로 변환\n",
    "        img = tensor[i].permute(1, 2, 0).cpu().numpy()\n",
    "        img = (img - img.min()) / (img.max() - img.min())  # 이미지 정규화\n",
    "\n",
    "        # 이미지 시각화 및 저장\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')  # 축 제거\n",
    "        file_path = os.path.join(save_dir, f'image_{i+1}.png')  # 파일 이름 설정\n",
    "        plt.savefig(file_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()  # 메모리 해제를 위해 close\n",
    "\n",
    "    print(f'{batch_size}개의 이미지가 {save_dir} 디렉토리에 저장되었습니다.')\n",
    "\n",
    "# 테스트용 가짜 텐서 생성\n",
    "dummy_tensor = torch.randn(23, 3, 224, 224)\n",
    "save_tensor_images(dummy_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABEL SMOOTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "similarity_matrix_0 = torch.tensor([[6.8477, 6.2773, 6.2773, 6.2344, 6.2344, 6.3555, 6.6016, 6.6016, 6.2383,\n",
    "         6.2383, 7.0273, 7.0273, 7.2109, 7.2109, 6.9922, 6.9922, 5.4336, 5.4336,\n",
    "         5.8672, 5.5625, 5.5625, 5.3828, 5.3828, 5.6562, 5.6562, 5.0312, 5.0312,\n",
    "         5.3359, 5.1758, 5.1758],\n",
    "        [6.1289, 5.9531,   float('-inf'), 5.6484, 5.6484, 5.8242, 6.3711, 6.3711, 5.8398,\n",
    "         5.8398, 6.6602, 6.6602, 6.3906, 6.3906, 6.6055, 6.6055, 5.2539, 5.2539,\n",
    "         5.4531, 5.0781, 5.0781, 5.4297, 5.4297, 5.6094, 5.6094, 5.3750, 5.3750,\n",
    "         5.4883, 5.2812, 5.2812],\n",
    "        [6.3906,   float('-inf'), 6.1094, 5.7344, 5.7344, 6.3398, 6.7734, 6.7734, 6.2773,\n",
    "         6.2773, 6.6719, 6.6719, 6.5547, 6.5547, 6.7500, 6.7500, 5.6523, 5.6523,\n",
    "         5.7148, 5.6523, 5.6523, 5.6328, 5.6328, 5.9531, 5.9531, 5.4922, 5.4922,\n",
    "         5.4688, 5.5625, 5.5625],\n",
    "        [5.7891, 4.7344, 4.7344, 4.9102,   float('-inf'), 4.9258, 5.4961, 5.4961, 4.9062,\n",
    "         4.9062, 6.2227, 6.2227, 6.7070, 6.7070, 6.3203, 6.3203, 4.8008, 4.8008,\n",
    "         5.4023, 4.7812, 4.7812, 4.5625, 4.5625, 5.0781, 5.0781, 5.0859, 5.0859,\n",
    "         4.7109, 4.2773, 4.2773],\n",
    "        [5.9727, 5.2344, 5.2344,   float('-inf'), 5.2109, 5.0898, 5.2578, 5.2578, 5.0977,\n",
    "         5.0977, 6.1250, 6.1250, 6.5742, 6.5742, 6.0469, 6.0469, 4.3984, 4.3984,\n",
    "         4.4297, 4.0352, 4.0352, 4.3789, 4.3789, 4.8867, 4.8867, 4.8945, 4.8945,\n",
    "         4.2930, 3.7070, 3.7070],\n",
    "        [6.6484, 6.1875, 6.1875, 5.8242, 5.8242, 6.7812, 6.8164, 6.8164, 6.4570,\n",
    "         6.4570, 7.0781, 7.0781, 6.9297, 6.9297, 7.1250, 7.1250, 6.5703, 6.5703,\n",
    "         6.4961, 6.4922, 6.4922, 6.3164, 6.3164, 6.4023, 6.4023, 6.2656, 6.2656,\n",
    "         5.7344, 6.0469, 6.0469],\n",
    "        [6.0664, 6.3281, 6.3281, 6.2852, 6.2852, 6.1758, 6.8320,   float('-inf'), 6.6133,\n",
    "         6.6133, 6.7070, 6.7070, 6.3828, 6.3828, 6.7031, 6.7031, 5.9180, 5.9180,\n",
    "         6.2734, 6.0703, 6.0703, 5.7461, 5.7461, 5.9141, 5.9141, 5.8008, 5.8008,\n",
    "         5.6484, 5.6719, 5.6719],\n",
    "        [6.5078, 6.6211, 6.6211, 6.6523, 6.6523, 6.3555,   float('-inf'), 7.2227, 6.9688,\n",
    "         6.9688, 6.8125, 6.8125, 6.9102, 6.9102, 6.9023, 6.9023, 6.1523, 6.1523,\n",
    "         6.3164, 6.2461, 6.2461, 5.8438, 5.8438, 5.8633, 5.8633, 5.7617, 5.7617,\n",
    "         5.6602, 5.8984, 5.8984],\n",
    "        [6.4844, 6.0586, 6.0586, 6.0703, 6.0703, 6.6562, 7.2695, 7.2695, 6.6250,\n",
    "           float('-inf'), 6.4219, 6.4219, 6.5000, 6.5000, 6.6289, 6.6289, 5.2031, 5.2031,\n",
    "         5.7031, 5.5117, 5.5117, 4.9570, 4.9570, 5.3125, 5.3125, 4.8555, 4.8555,\n",
    "         5.0469, 4.7109, 4.7109],\n",
    "        [6.8086, 6.1602, 6.1602, 6.2344, 6.2344, 6.2969, 6.8438, 6.8438,   float('-inf'),\n",
    "         6.0742, 6.7344, 6.7344, 6.8359, 6.8359, 6.9609, 6.9609, 5.4336, 5.4336,\n",
    "         5.9648, 5.4570, 5.4570, 5.5430, 5.5430, 5.9219, 5.9219, 5.7266, 5.7266,\n",
    "         5.6367, 5.1523, 5.1523],\n",
    "        [6.4961, 6.4219, 6.4219, 6.1992, 6.1992, 6.2891, 6.8750, 6.8750, 6.4492,\n",
    "         6.4492, 7.1602,   float('-inf'), 6.6797, 6.6797, 7.2109, 7.2109, 5.3203, 5.3203,\n",
    "         5.4961, 5.3711, 5.3711, 5.4883, 5.4883, 5.4922, 5.4922, 5.3867, 5.3867,\n",
    "         5.5391, 5.4688, 5.4688],\n",
    "        [6.8125, 6.3555, 6.3555, 6.2656, 6.2656, 6.1055, 6.8398, 6.8398, 6.3477,\n",
    "         6.3477,   float('-inf'), 6.9336, 6.7266, 6.7266, 7.0938, 7.0938, 5.7031, 5.7031,\n",
    "         6.1562, 5.7734, 5.7734, 5.3398, 5.3398, 5.8203, 5.8203, 5.2266, 5.2266,\n",
    "         5.2969, 5.1250, 5.1250],\n",
    "        [5.7539, 5.4414, 5.4414, 5.0703, 5.0703, 5.4961, 5.1250, 5.1250, 5.0430,\n",
    "         5.0430, 5.7109, 5.7109, 5.4102,   float('-inf'), 5.6055, 5.6055, 5.0977, 5.0977,\n",
    "         5.4805, 4.9141, 4.9141, 5.2773, 5.2773, 5.2578, 5.2578, 5.3047, 5.3047,\n",
    "         5.4102, 4.8125, 4.8125],\n",
    "        [6.1562, 5.4766, 5.4766, 5.3008, 5.3008, 5.5898, 5.5234, 5.5234, 5.1250,\n",
    "         5.1250, 6.5820, 6.5820,   float('-inf'), 6.4805, 6.4492, 6.4492, 5.3086, 5.3086,\n",
    "         5.8125, 5.2227, 5.2227, 5.2578, 5.2578, 5.5469, 5.5469, 5.3945, 5.3945,\n",
    "         5.5938, 5.1758, 5.1758],\n",
    "        [6.0117, 5.5625, 5.5625, 5.3672, 5.3672, 5.6367, 5.6211, 5.6211, 5.4336,\n",
    "         5.4336, 6.1094, 6.1094, 6.3945, 6.3945, 5.9609,   float('-inf'), 6.4453, 6.4453,\n",
    "         6.4570, 6.4609, 6.4609, 6.2422, 6.2422, 6.0234, 6.0234, 6.1914, 6.1914,\n",
    "         5.6914, 5.8633, 5.8633],\n",
    "        [5.4531, 5.3047, 5.3047, 5.1523, 5.1523, 5.6797, 5.7695, 5.7695, 5.6758,\n",
    "         5.6758, 6.1953, 6.1953, 5.8516, 5.8516,   float('-inf'), 6.0586, 5.7852, 5.7852,\n",
    "         5.7031, 5.7539, 5.7539, 5.6914, 5.6914, 5.3945, 5.3945, 5.4844, 5.4844,\n",
    "         5.3359, 5.6992, 5.6992]])\n",
    "\n",
    "similarity_matrix_1 = torch.torch.tensor([[6.8516, 6.1328, 6.3906, 5.7930, 5.9766, 6.6523, 6.0703, 6.5117, 6.4844,\n",
    "         6.8086, 6.5000, 6.8164, 5.7539, 6.1562, 6.0156, 5.4570, 6.1719, 6.1133,\n",
    "         6.6367, 6.3867, 5.9883, 6.7930, 6.3555, 6.4258, 6.0273, 6.5117, 6.5547,\n",
    "         6.1445, 5.9883, 6.1875],\n",
    "        [6.2812, 5.9531,   float('-inf'), 4.7344, 5.2344, 6.1914, 6.3281, 6.6250, 6.0625,\n",
    "         6.1562, 6.4219, 6.3594, 5.4414, 5.4766, 5.5664, 5.3086, 6.1328, 5.9102,\n",
    "         5.9414, 6.2031, 5.5469, 6.2617, 5.8906, 5.7305, 5.5664, 6.0977, 6.2383,\n",
    "         4.8906, 5.3750, 5.6758],\n",
    "        [6.2812,   float('-inf'), 6.1094, 4.7344, 5.2344, 6.1914, 6.3281, 6.6250, 6.0625,\n",
    "         6.1562, 6.4219, 6.3594, 5.4414, 5.4766, 5.5664, 5.3086, 6.1328, 5.9102,\n",
    "         5.9414, 6.2031, 5.5469, 6.2617, 5.8906, 5.7305, 5.5664, 6.0977, 6.2383,\n",
    "         4.8906, 5.3750, 5.6758],\n",
    "        [6.2344, 5.6484, 5.7344, 4.9062,   float('-inf'), 5.8242, 6.2852, 6.6523, 6.0703,\n",
    "         6.2305, 6.1992, 6.2656, 5.0703, 5.3008, 5.3672, 5.1523, 5.8945, 5.8672,\n",
    "         5.8242, 6.3789, 5.7461, 6.3242, 5.7070, 5.7891, 5.9102, 5.8906, 6.0820,\n",
    "         5.0195, 5.3203, 5.7188],\n",
    "        [6.2344, 5.6484, 5.7344,   float('-inf'), 5.2109, 5.8242, 6.2852, 6.6523, 6.0703,\n",
    "         6.2305, 6.1992, 6.2656, 5.0703, 5.3008, 5.3672, 5.1523, 5.8945, 5.8672,\n",
    "         5.8242, 6.3789, 5.7461, 6.3242, 5.7070, 5.7891, 5.9102, 5.8906, 6.0820,\n",
    "         5.0195, 5.3203, 5.7188],\n",
    "        [6.3555, 5.8281, 6.3398, 4.9258, 5.0938, 6.7812, 6.1797, 6.3555, 6.6602,\n",
    "         6.2969, 6.2891, 6.1055, 5.4961, 5.5898, 5.6367, 5.6836, 6.2188, 6.5469,\n",
    "         6.4688, 6.7109, 6.1094, 6.4844, 5.9453, 6.0117, 5.8672, 5.8125, 6.0391,\n",
    "         5.7930, 6.3203, 6.1797],\n",
    "        [6.6016, 6.3711, 6.7734, 5.4961, 5.2617, 6.8164, 6.8359,   float('-inf'), 7.2695,\n",
    "         6.8398, 6.8750, 6.8398, 5.1250, 5.5234, 5.6211, 5.7695, 6.8320, 7.2461,\n",
    "         6.5352, 7.3555, 6.6133, 6.9375, 6.0664, 6.0312, 5.9961, 5.6875, 5.8320,\n",
    "         5.7266, 6.4648, 6.3477],\n",
    "        [6.6016, 6.3711, 6.7734, 5.4961, 5.2617, 6.8164,   float('-inf'), 7.2227, 7.2695,\n",
    "         6.8398, 6.8750, 6.8398, 5.1250, 5.5234, 5.6211, 5.7695, 6.8320, 7.2461,\n",
    "         6.5352, 7.3555, 6.6133, 6.9375, 6.0664, 6.0312, 5.9961, 5.6875, 5.8320,\n",
    "         5.7266, 6.4648, 6.3477],\n",
    "        [6.2383, 5.8398, 6.2773, 4.9023, 5.0977, 6.4570, 6.6133, 6.9688, 6.6211,\n",
    "           float('-inf'), 6.4453, 6.3477, 5.0391, 5.1250, 5.4336, 5.6758, 6.2344, 6.5312,\n",
    "         6.4531, 6.5898, 6.0742, 6.4297, 5.7266, 5.4961, 5.8750, 5.4727, 5.4609,\n",
    "         5.0469, 5.7148, 5.6016],\n",
    "        [6.2383, 5.8398, 6.2773, 4.9023, 5.0977, 6.4570, 6.6133, 6.9688,   float('-inf'),\n",
    "         6.0703, 6.4453, 6.3477, 5.0391, 5.1250, 5.4336, 5.6758, 6.2344, 6.5312,\n",
    "         6.4531, 6.5898, 6.0742, 6.4297, 5.7266, 5.4961, 5.8750, 5.4727, 5.4609,\n",
    "         5.0469, 5.7148, 5.6016],\n",
    "        [7.0273, 6.6641, 6.6719, 6.2227, 6.1250, 7.0781, 6.7109, 6.8125, 6.4258,\n",
    "         6.7305, 7.1602,   float('-inf'), 5.7109, 6.5820, 6.1094, 6.1992, 6.8008, 6.2930,\n",
    "         6.7266, 6.6797, 6.8086, 7.1289, 6.3516, 6.6367, 6.1641, 6.8633, 6.5469,\n",
    "         6.6133, 6.8125, 6.3750],\n",
    "        [7.0273, 6.6641, 6.6719, 6.2227, 6.1250, 7.0781, 6.7109, 6.8125, 6.4258,\n",
    "         6.7305,   float('-inf'), 6.9375, 5.7109, 6.5820, 6.1094, 6.1992, 6.8008, 6.2930,\n",
    "         6.7266, 6.6797, 6.8086, 7.1289, 6.3516, 6.6367, 6.1641, 6.8633, 6.5469,\n",
    "         6.6133, 6.8125, 6.3750],\n",
    "        [7.2109, 6.3945, 6.5547, 6.7070, 6.5742, 6.9297, 6.3828, 6.9141, 6.5000,\n",
    "         6.8359, 6.6797, 6.7305, 5.4062,   float('-inf'), 6.3945, 5.8555, 6.4102, 6.1016,\n",
    "         6.5547, 6.3750, 6.4922, 6.6641, 5.9375, 6.4570, 5.6602, 6.5977, 6.1172,\n",
    "         6.5977, 6.5859, 5.7500],\n",
    "        [7.2109, 6.3945, 6.5547, 6.7070, 6.5742, 6.9297, 6.3828, 6.9141, 6.5000,\n",
    "         6.8359, 6.6797, 6.7305,   float('-inf'), 6.4805, 6.3945, 5.8555, 6.4102, 6.1016,\n",
    "         6.5547, 6.3750, 6.4922, 6.6641, 5.9375, 6.4570, 5.6602, 6.5977, 6.1172,\n",
    "         6.5977, 6.5859, 5.7500],\n",
    "        [6.9922, 6.6055, 6.7500, 6.3164, 6.0469, 7.1250, 6.7031, 6.9023, 6.6250,\n",
    "         6.9570, 7.2070, 7.0938, 5.6016, 6.4453, 5.9609,   float('-inf'), 6.8555, 6.4219,\n",
    "         6.6758, 6.9102, 6.7734, 7.1641, 6.2383, 6.7148, 6.2266, 6.8320, 6.5195,\n",
    "         6.5625, 6.9766, 6.5039],\n",
    "        [6.9922, 6.6055, 6.7500, 6.3164, 6.0469, 7.1250, 6.7031, 6.9023, 6.6250,\n",
    "         6.9570, 7.2070, 7.0938, 5.6016, 6.4453,   float('-inf'), 6.0586, 6.8555, 6.4219,\n",
    "         6.6758, 6.9102, 6.7734, 7.1641, 6.2383, 6.7148, 6.2266, 6.8320, 6.5195,\n",
    "         6.5625, 6.9766, 6.5039]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8693)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def label_smoothing(batch_size, smoothing=0.1):\n",
    "    confidence = 1.0 - smoothing\n",
    "    smooth_label = torch.full((batch_size, batch_size), smoothing / (batch_size - 1))\n",
    "    smooth_label.fill_diagonal_(confidence)\n",
    "    return smooth_label\n",
    "\n",
    "def contrastive_clip_loss_with_label_smoothing(image_embeddings, text_embeddings, temperature=0.07, smoothing=0.1):\n",
    "    # Normalize the embeddings\n",
    "    image_embeddings = F.normalize(image_embeddings, dim=-1)\n",
    "    text_embeddings = F.normalize(text_embeddings, dim=-1)\n",
    "    \n",
    "    # Compute the similarity scores\n",
    "    logits_per_image = torch.matmul(image_embeddings, text_embeddings.t()) / temperature\n",
    "    logits_per_text = logits_per_image.t()\n",
    "    \n",
    "    # Create smoothed target labels\n",
    "    batch_size = image_embeddings.size(0)\n",
    "    smoothed_labels = label_smoothing(batch_size, smoothing).to(image_embeddings.device)\n",
    "    \n",
    "    # Compute the cross-entropy loss using smoothed labels\n",
    "    loss_image = -torch.sum(smoothed_labels * F.log_softmax(logits_per_image, dim=-1), dim=-1).mean()\n",
    "    loss_text = -torch.sum(smoothed_labels * F.log_softmax(logits_per_text, dim=-1), dim=-1).mean()\n",
    "    \n",
    "    # Combine the losses\n",
    "    loss = (loss_image + loss_text) / 2.0\n",
    "    return loss\n",
    "\n",
    "# Example usage\n",
    "batch_size = 4\n",
    "embedding_dim = 512\n",
    "image_embeddings = torch.randn(batch_size, embedding_dim)\n",
    "text_embeddings = torch.randn(batch_size, embedding_dim)\n",
    "\n",
    "loss = contrastive_clip_loss_with_label_smoothing(image_embeddings, text_embeddings)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.8516,   -inf, 6.3906, 6.0703, 6.5117],\n",
      "        [5.7930, 5.9766, 6.6523, 6.1719, 6.1133]])\n",
      "tensor([[6.8086, 6.5000, 6.8164, 5.7539, 6.1562],\n",
      "        [  -inf, 6.3867, 5.9883, 6.7930, 6.3555]])\n",
      "torch.Size([2])\n",
      "tensor(1.3883)\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[-1.0297,    -inf, -1.4907, -1.8110, -1.3696],\n",
      "        [-2.0016, -1.8181, -1.1424, -1.6228, -1.6814]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "gather_out_cpu(): Expected dtype int64 for index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2334/4226030261.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoft_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelSmoothingCrossEntropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_matrix_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoft_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_matrix_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoft_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2334/4226030261.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, target, smoothing)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlogprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mnll_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlogprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mnll_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: gather_out_cpu(): Expected dtype int64 for index"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "    def forward(self, x, target, smoothing=0.1):\n",
    "        confidence = 1. - smoothing\n",
    "        logprobs = F.log_softmax(x, dim=-1)\n",
    "        print(logprobs)\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        print(nll_loss)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        print(smooth_loss)\n",
    "        loss = confidence * nll_loss + smoothing * smooth_loss\n",
    "        return loss.mean()\n",
    "    \n",
    "    \n",
    "# (y_one_hot * -F.log_softmax(z,dim=1)).sum(dim=1).mean()\n",
    "class LabelSmoothingCrossEntropy2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LabelSmoothingCrossEntropy2, self).__init__()\n",
    "    def forward(self, x, target, smoothing=0.1):\n",
    "        confidence = 1. - smoothing\n",
    "        logprobs = F.log_softmax(x, dim=-1)\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = confidence * nll_loss + smoothing * smooth_loss\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "num_queries = 2\n",
    "queue_size = 3\n",
    "\n",
    "# similarity_matrix_0 = torch.randn(num_queries, num_queries+queue_size)\n",
    "# similarity_matrix_1 = torch.randn(num_queries, num_queries+queue_size)\n",
    "\n",
    "similarity_matrix_0 = torch.tensor([[6.8516, float('-inf'), 6.3906, 6.0703, 6.5117],\n",
    "                                    [5.7930, 5.9766, 6.6523, 6.1719, 6.1133]])\n",
    "similarity_matrix_1 = torch.tensor([[6.8086, 6.5000, 6.8164, 5.7539, 6.1562],\n",
    "                                    [float('-inf'), 6.3867, 5.9883, 6.7930, 6.3555]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(similarity_matrix_0)\n",
    "print(similarity_matrix_1)\n",
    "\n",
    "# hard\n",
    "label = torch.arange(similarity_matrix_0.shape[0])\n",
    "print(label.shape)\n",
    "hard_loss = 0.5 * F.cross_entropy(similarity_matrix_0, label) \\\n",
    "       + 0.5 * F.cross_entropy(similarity_matrix_1, label)\n",
    "print(hard_loss)\n",
    "\n",
    "# soft 1\n",
    "soft_label = torch.zeros_like(similarity_matrix_0)\n",
    "print(soft_label)\n",
    "criterion = LabelSmoothingCrossEntropy()\n",
    "loss = 0.5 * criterion(similarity_matrix_0, soft_label, smoothing=0.1) \\\n",
    "    + 0.5 * criterion(similarity_matrix_1, soft_label, smoothing=0.1)\n",
    "print(loss)\n",
    "\n",
    "# soft 2\n",
    "soft_label2 = torch.zeros_like(similarity_matrix_0)\n",
    "soft_label2.fill_diagonal_(1)\n",
    "print(soft_label2)\n",
    "criterion2 = LabelSmoothingCrossEntropy2()\n",
    "# loss2 = 0.5 * criterion2(similarity_matrix_0, soft_label2, smoothing=0.1) \\\n",
    "#     + 0.5 * criterion2(similarity_matrix_1, soft_label2, smoothing=0.1)\n",
    "# print(loss2)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False, False],\n",
      "        [False, False,  True, False, False],\n",
      "        [False,  True, False, False, False],\n",
      "        [False, False, False, False,  True],\n",
      "        [False, False, False,  True, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "seq_ids=torch.tensor([  4.,  54.,  54., 654., 654.])\n",
    "label_mask = seq_ids[None] == seq_ids[:, None]\n",
    "label_mask.fill_diagonal_(False)\n",
    "print(label_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28512/2244284.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLabelSmoothingCrossEntropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLabelSmoothingCrossEntropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "arange(): argument 'end' (position 1) must be Number, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28512/3340014220.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mhard_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecover_soft_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hard'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: arange(): argument 'end' (position 1) must be Number, not list"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.functional as F\n",
    "\n",
    "def Recover_soft_label(label, label_type, n_classes):\n",
    "    if label_type == 'hard':\n",
    "        return torch.zeros(label.size(0), n_classes).scatter_(1, label.view(-1, 1), 1)\n",
    "    else:\n",
    "        index = label[:,0].to(dtype=int)\n",
    "        value = label[:,1]\n",
    "        minor_value = (torch.ones_like(value) - value)/(n_classes-1)\n",
    "        minor_value = minor_value.reshape(-1,1).repeat_interleave(n_classes, dim=1)\n",
    "        soft_label = (minor_value * torch.ones(index.size(0), n_classes)).scatter_(1, index.view(-1, 1), value.view(-1, 1))\n",
    "        return soft_label\n",
    "    \n",
    "batch_size = 10\n",
    "label = torch.arange([batch_size, 16])\n",
    "print(label)\n",
    "hard_label = Recover_soft_label(label, 'hard', 16)\n",
    "print(hard_label)\n",
    "soft_label = Recover_soft_label(label, 'soft', 16)\n",
    "print(soft_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Matrix 0 (Text as Query):\n",
      "similarity_matrix_0.shape :  torch.Size([16, 30])\n",
      "Similarity Matrix 1 (Image as Query):\n",
      "similarity_matrix_1.shape :  torch.Size([16, 30])\n",
      "label: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28512/875036314.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Compute contrastive loss with label smoothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mloss_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrastive_loss_with_label_smoothing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_matrix_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mloss_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrastive_loss_with_label_smoothing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_matrix_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_28512/875036314.py\u001b[0m in \u001b[0;36mcontrastive_loss_with_label_smoothing\u001b[0;34m(similarity_matrix, labels, smoothing)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLoss\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0msmoothed_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothed_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_28512/875036314.py\u001b[0m in \u001b[0;36mlabel_smoothing\u001b[0;34m(labels, smoothing)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \"\"\"\n\u001b[1;32m     13\u001b[0m     \u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mlabel_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrue_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def label_smoothing(labels, smoothing=0.1):\n",
    "    \"\"\"\n",
    "    Apply label smoothing.\n",
    "    Args:\n",
    "        labels (torch.Tensor): Ground truth labels.\n",
    "        smoothing (float): Smoothing factor.\n",
    "    Returns:\n",
    "        torch.Tensor: Smoothed labels.\n",
    "    \"\"\"\n",
    "    confidence = 1.0 - smoothing\n",
    "    label_shape = torch.Size((labels.size(0), labels.size(1)))\n",
    "    with torch.no_grad():\n",
    "        true_dist = torch.empty(size=label_shape, device=labels.device)\n",
    "        true_dist.fill_(smoothing / (labels.size(1) - 1))\n",
    "        true_dist.scatter_(1, labels.data.unsqueeze(1), confidence)\n",
    "    return true_dist\n",
    "\n",
    "def contrastive_loss_with_label_smoothing(similarity_matrix, labels, smoothing=0.1):\n",
    "    \"\"\"\n",
    "    Compute contrastive loss with label smoothing.\n",
    "    Args:\n",
    "        similarity_matrix (torch.Tensor): Similarity matrix.\n",
    "        labels (torch.Tensor): Ground truth labels.\n",
    "        smoothing (float): Smoothing factor.\n",
    "    Returns:\n",
    "        torch.Tensor: Loss value.\n",
    "    \"\"\"\n",
    "    smoothed_labels = label_smoothing(labels, smoothing)\n",
    "    loss = F.cross_entropy(similarity_matrix, smoothed_labels)\n",
    "    return loss\n",
    "\n",
    "# Ensure similarity matrices are 2D\n",
    "assert similarity_matrix_0.dim() == 2, \"similarity_matrix_0 must be a 2D matrix\"\n",
    "assert similarity_matrix_1.dim() == 2, \"similarity_matrix_1 must be a 2D matrix\"\n",
    "\n",
    "\n",
    "num_queries = similarity_matrix_0.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "# Print similarity matrices for debugging\n",
    "print(f\"Similarity Matrix 0 (Text as Query):\")\n",
    "print(\"similarity_matrix_0.shape : \", similarity_matrix_0.shape)\n",
    "# print(similarity_matrix_0)\n",
    "\n",
    "print(f\"Similarity Matrix 1 (Image as Query):\")\n",
    "print(\"similarity_matrix_1.shape : \", similarity_matrix_1.shape)\n",
    "# print(similarity_matrix_1)\n",
    "\n",
    "# Generate labels\n",
    "\n",
    "label = torch.arange(num_queries)\n",
    "print('label:', label)\n",
    "\n",
    "# Compute contrastive loss with label smoothing\n",
    "loss_0 = contrastive_loss_with_label_smoothing(similarity_matrix_0, label, smoothing=0.1)\n",
    "loss_1 = contrastive_loss_with_label_smoothing(similarity_matrix_1, label, smoothing=0.1)\n",
    "\n",
    "# Combine the losses\n",
    "loss = 0.5 * loss_0 + 0.5 * loss_1\n",
    "losses = dict(loss_bag=loss * self.bag_weight)\n",
    "\n",
    "# Enqueue\n",
    "queues_update = dict(clip_text_features=torch.cat([clip_text_features,\n",
    "                                                   img_ids.view(-1, 1)], dim=-1).detach(),\n",
    "                     clip_image_features=torch.cat([clip_image_features,\n",
    "                                                    img_ids.view(-1, 1)], dim=-1).detach()\n",
    "                     )\n",
    "\n",
    "if similarity_matrix_0.shape[1] > 40:\n",
    "    # Additional code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sequences:  [\n",
    "    tensor([[ -5.9375,  15.4375,  -7.3984,  ...,   0.0742,  -9.7812,  -0.5078],\n",
    "        [ -7.5273,   6.5078,  -5.8047,  ...,  -2.8398, -13.1094,   8.0391],\n",
    "        [ -4.9844,   4.3242, -11.0078,  ...,  -1.5518,  -7.1758,   2.7949]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>),\n",
    "    \n",
    "    tensor([[ 5.8350e-01,  3.5977e+00, -7.1250e+00,  ...,  5.9961e+00,\n",
    "         -7.5000e+00, -3.9727e+00],\n",
    "        [-2.0430e+00,  3.7949e+00, -1.3574e+00,  ...,  2.6133e+00,\n",
    "         -6.4648e+00, -4.5117e+00],\n",
    "        [ 9.7656e-03,  6.2383e+00, -5.1055e+00,  ...,  9.4688e+00,\n",
    "         -1.0422e+01, -8.4531e+00],\n",
    "        ...,\n",
    "        [ 1.8574e+00, -1.9424e+00, -1.1328e-01,  ..., -2.8418e+00,\n",
    "         -6.2188e+00, -7.2578e+00],\n",
    "        [-5.7031e-01, -1.6074e+00, -2.8301e+00,  ...,  6.9766e+00,\n",
    "         -4.7188e+00, -1.4820e+01],\n",
    "        [-5.4004e-01, -1.2773e+00, -9.3594e+00,  ...,  5.1914e+00,\n",
    "         -8.6875e+00, -2.1934e+00]], device='cuda:0', dtype=torch.float16,\n",
    "       grad_fn=<IndexBackward>),\n",
    "    \n",
    "    tensor([[ 0.1816, -2.4336, -8.2109,  ...,  5.8047, -5.1172, -3.1094],\n",
    "        [-0.6392, -0.8906, -4.7500,  ...,  5.0586, -6.3945, -5.3086],\n",
    "        [-0.5400, -1.2773, -9.3594,  ...,  5.1914, -8.6875, -2.1934],\n",
    "        ...,\n",
    "        [ 1.9121,  5.3164, -2.0137,  ...,  7.8789, -7.2031, -4.3047],\n",
    "        [-0.0493, -0.4512, -4.7734,  ...,  6.2656, -7.5156,  2.2285],\n",
    "        [ 1.8574, -1.9424, -0.1133,  ..., -2.8418, -6.2188, -7.2578]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>),\n",
    "    \n",
    "    tensor([[-1.5127, -1.4609, -5.8359,  ...,  6.2344, -4.8164, -4.8945],\n",
    "        [-0.7690, -0.0410, -3.1309,  ...,  4.5430, -5.8281, -2.8535],\n",
    "        [-0.0806,  5.2734, -3.7949,  ...,  6.3438, -6.1875, -8.3438],\n",
    "        ...,\n",
    "        [ 0.9038,  1.5039, -3.9355,  ...,  8.2188, -4.5195, -4.3008],\n",
    "        [ 0.8027,  1.8418, -9.1875,  ...,  7.3438, -7.8906,  0.8086],\n",
    "        [-2.3477, -1.9678, -3.4414,  ...,  3.3105,  1.0723, -6.1445]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ 0.4431, -1.3184, -5.9922,  ...,  9.6797, -3.4023, -5.3242],\n",
    "        [-2.0664,  7.2656, -6.9453,  ...,  3.3359, -6.3281, -9.6250],\n",
    "        [ 1.4014, -2.1523, -8.8359,  ...,  6.0938, -3.6426, -1.0010],\n",
    "        [-1.5127, -1.4609, -5.8359,  ...,  6.2344, -4.8164, -4.8945],\n",
    "        [-0.0806,  5.2734, -3.7949,  ...,  6.3438, -6.1875, -8.3438],\n",
    "        [-1.6406, -3.5996, -3.9883,  ...,  0.9111, -1.2031, -5.7344]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[-0.9282, 11.0234, -9.1719,  ...,  3.4336, -8.1094, -5.1680],\n",
    "        [-4.5117,  4.4609, -8.8438,  ...,  1.6904, -3.8105,  1.3008]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -1.9053,   2.5195,  -5.2305,  ...,   4.8516,  -1.8516, -11.9219],\n",
    "        [ -2.7090,   1.0938,  -4.9180,  ...,   2.1250,  -4.7578,  -4.8867],\n",
    "        [  0.2646,   5.1094,  -4.4492,  ...,   5.8984,  -7.0156,  -5.8203],\n",
    "        [ -2.7988,  -0.9678,  -4.0898,  ...,   0.4536,  -3.0586,  -7.1641],\n",
    "        [  0.5430,   2.8145, -11.2344,  ...,   5.5703,  -8.9609,   0.1562],\n",
    "        [ -3.5078,   0.6670,  -3.5430,  ...,   2.8516,  -0.7852,  -7.5742]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -2.1250,   4.9219,  -6.1406,  ...,   7.9609,  -0.7847, -13.1797],\n",
    "        [ -0.1492,  -0.5688,  -5.6953,  ...,   8.8125,  -3.9160,  -2.7578],\n",
    "        [  0.5430,   2.8145, -11.2344,  ...,   5.5703,  -8.9609,   0.1562],\n",
    "        [  0.2646,   5.1094,  -4.4492,  ...,   5.8984,  -7.0156,  -5.8203],\n",
    "        [ -1.3516,   1.5137,  -8.9766,  ...,   4.0625,  -8.2812,  -1.5859],\n",
    "        [ -2.7988,  -0.9678,  -4.0898,  ...,   0.4536,  -3.0586,  -7.1641]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[  0.0296,   3.1855, -10.5781,  ...,   4.6953,  -5.8828,   0.2812],\n",
    "        [  0.4795,   1.6250,  -3.6816,  ...,   6.7461,  -8.5781,   6.6719],\n",
    "        [ -2.0273,   2.7344,  -2.4219,  ...,   3.3516,  -3.0996,  -1.3965],\n",
    "        [  5.4922,   8.7109,  -7.0430,  ...,  10.3906,  -9.6641,   0.2266],\n",
    "        [  0.0350,   2.5977, -10.5625,  ...,   1.6748, -10.6562,   3.2891],\n",
    "        [ -1.1895,   0.5811,  -4.2812,  ...,   3.3750,  -6.1719,  -7.2500]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -0.1670,   8.5156,  -5.8047,  ...,   6.0781,  -5.3398,  -7.2109],\n",
    "        [  0.4795,   1.6250,  -3.6816,  ...,   6.7461,  -8.5781,   6.6719],\n",
    "        [  5.4922,   8.7109,  -7.0430,  ...,  10.3906,  -9.6641,   0.2266],\n",
    "        ...,\n",
    "        [  0.7402,   8.7656,  -8.6641,  ...,  10.0547,  -2.6035,   0.2773],\n",
    "        [  0.0296,   3.1855, -10.5781,  ...,   4.6953,  -5.8828,   0.2812],\n",
    "        [ -3.6523,   5.3594,  -4.1016,  ...,   4.6211,  -0.3652,  -7.7852]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[  0.6250,   7.7773,  -8.5391,  ...,   5.0508, -11.9219,   9.5859],\n",
    "        [ -6.1133,   4.6094,  -5.9453,  ...,  -1.3438,  -8.5781,   7.9688],\n",
    "        [  3.2773,  12.5078, -10.7031,  ...,   4.9844, -11.1094,   0.3242],\n",
    "        [ -2.9434,   6.4805, -12.5000,  ...,  -3.7734, -10.2422,   8.0000],\n",
    "        [ -2.0918,   4.3242,  -9.5312,  ...,   2.2148,  -9.0469,   1.6172]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ 1.3184,  1.8379, -4.7852,  ...,  7.5117, -4.9141,  1.1660],\n",
    "        [-0.5645,  0.1542, -3.1172,  ...,  2.3945, -4.9375,  3.2891]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[-0.5645,  0.1542, -3.1172,  ...,  2.3945, -4.9375,  3.2891],\n",
    "        [-2.9883, -1.6123, -6.4922,  ..., -1.2637, -9.1016,  2.4980],\n",
    "        [ 1.0488, -4.4453, -5.3477,  ...,  1.8193, -1.2822, -6.5625],\n",
    "        [ 1.3184,  1.8379, -4.7852,  ...,  7.5117, -4.9141,  1.1660],\n",
    "        [ 0.1320,  1.4883, -7.4766,  ...,  4.0078, -7.4531,  4.1406]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -1.0039,   5.1758, -12.0391,  ...,   4.8359, -10.2656,   7.3750],\n",
    "        [ -8.0703,   4.7734, -10.0156,  ...,  -0.1836,  -8.8906,   4.8008],\n",
    "        [ -4.8320,   4.2500,  -8.7188,  ...,   4.6914,  -4.1406,  -6.1641]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -1.2412,  -4.0547,  -3.8242,  ...,   5.6641,   1.4199, -11.8750],\n",
    "        [ -0.8906,  -1.2139,  -3.3945,  ...,   3.3320,  -4.5547,  -1.1094],\n",
    "        [  2.2969,   3.1406,  -6.4180,  ...,   7.0273,  -7.8516,  -4.3008],\n",
    "        [ -1.3730,  -5.2656,  -3.9531,  ...,   3.4102,  -5.0312,  -7.2070]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -0.8906,  -1.2139,  -3.3945,  ...,   3.3320,  -4.5547,  -1.1094],\n",
    "        [  2.2969,   3.1406,  -6.4180,  ...,   7.0273,  -7.8516,  -4.3008],\n",
    "        [ -0.1949,   0.2891,  -8.0547,  ...,  -0.9590,  -7.8867,   3.4609],\n",
    "        [ -4.9023,  -0.1152,  -4.9492,  ...,   7.4688,  -2.3926, -10.8672],\n",
    "        [ -1.2412,  -4.0547,  -3.8242,  ...,   5.6641,   1.4199, -11.8750]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -2.4883,  -3.7148, -10.0859,  ...,   4.5547,  -1.3613,  -0.2275],\n",
    "        [ -0.0415,  -0.5513,  -5.5039,  ...,   6.9219,  -4.2344,  -0.6797],\n",
    "        [  0.3335,  -3.0059,  -3.3359,  ...,   8.1719,   1.5986, -11.6406],\n",
    "        ...,\n",
    "        [ -2.5039,   0.1406,  -9.7734,  ...,   1.4854,  -8.3438,   5.7578],\n",
    "        [ -1.2412,  -4.0547,  -3.8242,  ...,   5.6641,   1.4199, -11.8750],\n",
    "        [ -4.5508,   0.3887,  -6.2422,  ...,   2.3750,  -5.4375,  -5.4023]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -0.4746,  -2.0352,  -8.4844,  ...,   5.3945,  -4.0000,  -0.8379],\n",
    "        [ -1.2412,  -4.0547,  -3.8242,  ...,   5.6641,   1.4199, -11.8750],\n",
    "        [ -3.3789,  -0.3887,  -5.2344,  ...,   8.7188,  -2.8711, -11.1016],\n",
    "        ...,\n",
    "        [ -4.5508,   0.3887,  -6.2422,  ...,   2.3750,  -5.4375,  -5.4023],\n",
    "        [ -0.4236,   0.4419,  -4.1055,  ...,   2.9297,  -6.8711,   0.4961],\n",
    "        [ -0.5625,  -3.4121,  -5.2812,  ...,   0.7710,  -3.4785,  -5.8242]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -0.5703,   0.8047,  -5.5742,  ...,  -1.1074,  -4.8516,  -5.3984],\n",
    "        [ -0.0703,  -3.1992,  -9.3828,  ...,   4.1328,  -0.5605,   4.5508],\n",
    "        [  1.6523,  -1.7305,  -7.7461,  ...,   3.0020,  -6.0312,   3.7363],\n",
    "        ...,\n",
    "        [  0.6621,   0.2734,  -3.2852,  ...,   5.7812,  -0.3545, -15.5625],\n",
    "        [  2.5430,  -1.4229,  -2.8281,  ...,   8.0469,  -4.4375,  -5.1992],\n",
    "        [  2.0625,   5.7031,  -7.0703,  ...,   6.6523,  -6.6914,  -9.7578]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -3.6328,   5.3516,  -4.9727,  ...,   7.6445,   3.1523, -17.6562],\n",
    "        [ -0.5176,  -0.5430, -12.9297,  ...,   8.3125,   0.9668,  -2.7852],\n",
    "        [ -7.6211,   2.1777,  -2.2559,  ...,   4.5703,   1.4385, -13.2500],\n",
    "        ...,\n",
    "        [  4.4258,   0.1747,  -4.2031,  ...,   2.9102,  -3.8008,   2.4180],\n",
    "        [  1.5000,   3.2500,  -6.4062,  ...,   4.3828,  -2.5000,  -5.4922],\n",
    "        [  2.9102,   0.8398,  -3.9727,  ...,  -2.8770,  -1.8672,  -4.1328]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -3.4355,  15.1719,  -9.5312,  ...,  -0.1963,  -6.0938,  -2.5156],\n",
    "        [  1.1602,   5.9766,  -8.1797,  ...,   5.8867, -10.1094,   7.4297],\n",
    "        [ -4.6641,   7.9219, -10.2500,  ...,  -2.0078,  -5.5391,  -7.2188]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[-3.4648,  9.7188, -5.7031,  ..., -2.0938, -5.6055, -1.1562],\n",
    "        [-1.0078,  2.7344, -6.1406,  ..., -1.2656, -1.2822, -5.9609],\n",
    "        [-3.9277, 11.1484, -6.7266,  ...,  1.1602, -4.0195, -4.5156],\n",
    "        [ 0.2646,  6.8242, -4.5078,  ...,  5.1133, -7.2656,  2.0625],\n",
    "        [-2.4805,  8.4062, -5.0391,  ..., -2.4297, -6.9766,  5.1523],\n",
    "        [-0.9546,  1.8682, -8.3516,  ..., -0.6641, -1.0889, -7.3945]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -3.9277,  11.1484,  -6.7266,  ...,   1.1602,  -4.0195,  -4.5156],\n",
    "        [  0.0820,  10.9766, -11.4453,  ...,   2.4570,  -4.9219,  -8.2109],\n",
    "        [ -3.4648,   9.7188,  -5.7031,  ...,  -2.0938,  -5.6055,  -1.1562],\n",
    "        [  3.4336,  -2.6660, -12.0625,  ...,   3.6973,  -5.8672,   5.6523],\n",
    "        [  3.0312,   0.1250,  -3.2461,  ...,   1.1602,  -5.0977,   3.6445]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[-3.2832, 11.6719, -8.5547,  ...,  0.7705, -4.8828, -9.6562],\n",
    "        [-2.8672,  6.9414, -7.0703,  ...,  2.3047, -2.6523, -5.4648]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -0.5488,   4.8125,  -7.5820,  ...,   5.6680,  -2.4043,   0.0527],\n",
    "        [ -0.6514,   9.9922,  -8.0391,  ...,   6.1875,  -5.2812,  -5.0586],\n",
    "        [  0.7314,  -0.6025,  -6.7266,  ...,   2.5020,   0.9463,  -6.0078],\n",
    "        ...,\n",
    "        [  1.9062,  -1.2168, -12.6875,  ...,   3.4375,  -4.6797,   0.0303],\n",
    "        [  3.2324,   1.5967,  -5.6055,  ...,   2.7305,  -5.2109,  -2.4648],\n",
    "        [  4.3750,  -2.1934, -12.6016,  ...,   1.5908,  -4.8242,   0.5625]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[  0.0986,   8.2031,  -7.2031,  ...,   8.5000,  -3.6250,  -5.9609],\n",
    "        [ -1.1191,   1.6758,  -5.8438,  ...,   3.1758,  -1.6729, -10.5703],\n",
    "        [  1.6650,   3.4922,  -3.0371,  ...,   5.4375,  -2.9258,  -1.1514],\n",
    "        ...,\n",
    "        [  2.7734,   2.8984,  -4.3203,  ...,   4.8594,  -1.5234,  -3.4023],\n",
    "        [  0.2065,   6.8906,  -6.5469,  ...,   6.8203,  -4.0039,  -5.3945],\n",
    "        [  0.8633,   0.0312,  -9.7656,  ...,   2.0918,  -4.0625,   0.1133]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ 1.2695,  0.7217, -7.8281,  ...,  4.3438, -1.1084, -4.3711],\n",
    "        [ 0.2065,  6.8906, -6.5469,  ...,  6.8203, -4.0039, -5.3945],\n",
    "        [-1.2510, -2.2109, -3.1641,  ...,  1.6855,  0.8203, -6.1602],\n",
    "        ...,\n",
    "        [-0.6626, -2.0000, -3.8809,  ...,  2.0820,  0.1650, -8.5312],\n",
    "        [ 0.3828,  5.1367, -5.3477,  ...,  7.1172, -0.7422, -5.4531],\n",
    "        [ 0.7222, -0.6836, -8.7812,  ...,  7.9375, -3.8945, -1.1914]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -4.6836,  11.1719,  -8.1016,  ...,  -2.2480,  -5.6445,   1.5820],\n",
    "        [ -2.5117,  11.2031, -10.5391,  ...,   1.8066,  -5.6953,  -6.9023],\n",
    "        [ -3.5840,  17.6094,  -9.2422,  ...,   0.3206,  -2.9336,  -3.2109],\n",
    "        [ -0.6152,   7.4766, -13.2812,  ...,   5.5312,  -1.6582,  -1.9775],\n",
    "        [ -1.1104,  14.0312, -10.8047,  ...,   3.3164,  -2.6836,  -8.8359]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[  1.3252,   5.6758,  -4.0547,  ...,   4.4648,  -4.4180,   2.5469],\n",
    "        [ -0.7178,   4.5703,  -3.7891,  ...,   2.3262,  -8.4062,   7.5469],\n",
    "        [ -2.5117,  11.2031, -10.5391,  ...,   1.8066,  -5.6953,  -6.9023]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -2.1406,   5.0625, -10.2734,  ...,   2.6367, -12.0312,  13.8359],\n",
    "        [ -4.7891,   3.9102, -11.7500,  ...,  -4.8633,  -8.4844,   8.3438],\n",
    "        [ -3.4570,   3.6152, -13.5312,  ...,  -6.7812, -11.0000,   6.9258]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -1.8379,   0.8438,  -5.5898,  ...,   3.2246,  -0.8799, -12.6719],\n",
    "        [ -2.3359,  -3.8340,  -3.6328,  ...,   9.1250,  -2.7461, -12.1328],\n",
    "        [ -2.8867,  -3.0859,  -9.0938,  ...,   5.8164,  -1.8418,   1.3369],\n",
    "        ...,\n",
    "        [  0.0918,  -4.3516,  -2.0098,  ...,   0.8418,  -3.6328,  -6.4727],\n",
    "        [  1.0977,  -4.0156,  -3.4004,  ...,   4.4609,  -4.4883,   0.1719],\n",
    "        [  3.7070,  -5.0586,  -1.4805,  ...,  -0.7119,  -2.3867,  -6.2891]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[  3.7070,  -5.0586,  -1.4805,  ...,  -0.7119,  -2.3867,  -6.2891],\n",
    "        [ -1.8379,   0.8438,  -5.5898,  ...,   3.2246,  -0.8799, -12.6719],\n",
    "        [  2.4883,  -2.0371, -10.1875,  ...,   3.1484,  -4.5625,  -4.2070],\n",
    "        ...,\n",
    "        [  0.7246,  -2.3125,  -8.3906,  ...,   3.0762,  -9.0469,   0.2148],\n",
    "        [  1.8271,  -0.6406,  -2.5605,  ...,   7.7812,  -2.5547, -11.7344],\n",
    "        [  0.5635,  -5.4102,  -1.9268,  ...,   5.8359,  -3.5645,  -7.9805]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -3.9688,   2.2480,  -6.5000,  ...,   6.0156,   1.1680, -12.1797],\n",
    "        [ -3.7871,   0.3828,  -7.8594,  ...,   1.5898,  -2.2363,  -7.2461],\n",
    "        [ -0.7578,   0.4946,  -5.2969,  ...,   2.7637,  -5.0859,   0.9043],\n",
    "        ...,\n",
    "        [  3.3223,   0.6006,  -5.3281,  ...,   3.8809,  -4.2422,   2.4336],\n",
    "        [  2.6211,   5.1641,  -9.7188,  ...,   6.0938,  -7.5547,  -1.8926],\n",
    "        [  1.9531,  -3.8398,  -6.7305,  ...,   0.9771,  -3.5117,  -6.5547]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -0.7578,   0.4946,  -5.2969,  ...,   2.7637,  -5.0859,   0.9043],\n",
    "        [ -2.2031,  -0.9644, -15.6719,  ...,  10.4766,  -3.9746,   2.7539],\n",
    "        [ -3.9688,   2.2480,  -6.5000,  ...,   6.0156,   1.1680, -12.1797],\n",
    "        [ -1.5264,  -0.8115,  -6.6602,  ...,   5.1172,  -5.2188,   5.4141],\n",
    "        [  2.6211,   5.1641,  -9.7188,  ...,   6.0938,  -7.5547,  -1.8926],\n",
    "        [  1.9531,  -3.8398,  -6.7305,  ...,   0.9771,  -3.5117,  -6.5547]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[  0.6548,  -2.2246,  -9.3984,  ...,   3.2539,  -4.5000,  -3.2188],\n",
    "        [ -2.0566,  -2.1250,  -6.3594,  ...,   8.4766,  -3.3105,  -4.2266],\n",
    "        [ -0.8330,   3.2793,  -4.3828,  ...,   5.8008,   0.3857,  -8.6094],\n",
    "        ...,\n",
    "        [ -0.4844,   2.2344,  -6.3281,  ...,   7.8047,   0.8740, -12.5078],\n",
    "        [ -0.0508,   2.6914,  -3.1875,  ...,   4.9922,  -0.8105,  -5.7734],\n",
    "        [  3.7051,   5.0430,  -6.3711,  ...,  11.4844,  -3.2852,  -5.1172]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[-0.8330,  3.2793, -4.3828,  ...,  5.8008,  0.3857, -8.6094],\n",
    "        [ 1.3506,  3.7910, -5.0352,  ..., 10.3594, -2.3047, -7.5312],\n",
    "        [ 0.8735, -1.8340, -7.8125,  ...,  7.6484, -1.9678, -3.8242],\n",
    "        ...,\n",
    "        [-0.8750,  0.6504, -6.4531,  ...,  7.6055, -3.5527, -2.8457],\n",
    "        [ 3.7051,  5.0430, -6.3711,  ..., 11.4844, -3.2852, -5.1172],\n",
    "        [-1.5400,  0.0117, -1.7236,  ...,  3.6816, -2.4629, -8.8281]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[-2.7383, -1.8320, -7.4648,  ...,  7.7031, -1.9180, -3.0820],\n",
    "        [-1.4717,  3.6348, -4.6094,  ...,  5.3203, -0.8926, -5.1094],\n",
    "        [ 0.7754,  5.9102, -6.3438,  ...,  8.3047, -0.8809, -6.5586],\n",
    "        ...,\n",
    "        [-1.4756,  4.2734, -6.7188,  ...,  6.5859, -3.0293, -2.0215],\n",
    "        [-5.4805,  2.0801, -4.2266,  ...,  2.8691, -5.4062,  1.6855],\n",
    "        [-2.5703, -2.7656, -5.4531,  ..., -0.4531, -1.6621, -1.9590]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[-5.3633,  1.9189, -5.0078,  ...,  1.4150, -1.8936, -3.2500],\n",
    "        [-2.3008,  1.8965, -0.7637,  ...,  2.4434, -3.1172,  1.6699],\n",
    "        [-2.7383, -1.8320, -7.4648,  ...,  7.7031, -1.9180, -3.0820],\n",
    "        [ 0.7754,  5.9102, -6.3438,  ...,  8.3047, -0.8809, -6.5586],\n",
    "        [-1.4590,  1.0605, -6.3242,  ...,  2.1504, -5.3555,  0.1211]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -1.3193,   5.2188,  -5.6094,  ...,   7.2969,   0.6895, -10.2344],\n",
    "        [  0.3687,  -1.2988,  -9.3906,  ...,   8.8594,  -0.8535,  -6.7969],\n",
    "        [  2.5527,   4.1133,  -4.6328,  ...,   7.8984,  -2.5312,  -3.8945],\n",
    "        ...,\n",
    "        [ -4.0625,   2.6172,  -6.9492,  ...,   7.5859,  -0.6797, -11.2578],\n",
    "        [ -0.7310,   4.6172,  -6.8203,  ...,   2.6719,   1.4531,  -7.3672],\n",
    "        [  1.3447,  -1.2148,  -4.9805,  ...,   2.3320,   1.7344,  -4.2734]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[  0.9292,   5.9062,  -8.1875,  ...,   4.6133,  -1.4023,  -7.7344],\n",
    "        [ -1.6270,   1.2695,  -8.3594,  ...,   3.1953,  -2.0645,   2.0723],\n",
    "        [ -1.0898,   5.1875,  -5.6836,  ...,   7.1797,   0.6152, -10.6719],\n",
    "        ...,\n",
    "        [ -4.0625,   2.6172,  -6.9492,  ...,   7.5859,  -0.6797, -11.2578],\n",
    "        [ -0.2461,   0.8120,  -6.1484,  ...,   8.1562,  -4.5742,  -4.3867],\n",
    "        [  0.1921,   3.7266,  -7.3203,  ...,   6.4766,  -2.1094,  -9.6328]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -1.2529,   6.7656, -14.2500,  ...,   7.2578,  -4.8555,  -2.9297],\n",
    "        [ -2.6641,   7.4805,  -4.5078,  ...,   3.5059,  -6.5469,   4.3398],\n",
    "        [ -0.9233,  13.1875,  -9.0391,  ...,   7.1484,  -2.5312,  -8.6406],\n",
    "        ...,\n",
    "        [ -6.3867,   2.9121,  -2.8086,  ...,  -1.8809,  -9.2969,   8.5000],\n",
    "        [ -4.0352,   7.9727,  -9.3672,  ...,   1.6367,  -4.6250,  -2.6133],\n",
    "        [ -3.2695,  -1.7363, -10.2188,  ...,  -2.3398,  -3.9844,   5.5156]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -7.0859,   4.3516,  -5.6055,  ...,   0.5981,  -4.8984,   3.9961],\n",
    "        [ -3.2695,  -1.7363, -10.2188,  ...,  -2.3398,  -3.9844,   5.5156],\n",
    "        [ -1.2529,   6.7656, -14.2500,  ...,   7.2578,  -4.8555,  -2.9297],\n",
    "        [ -2.6641,   7.4805,  -4.5078,  ...,   3.5059,  -6.5469,   4.3398],\n",
    "        [ -2.8008,   7.1133,  -8.6250,  ...,   1.9434,  -5.0703,   0.8438],\n",
    "        [ -0.3462,   4.5195,  -7.1875,  ...,   3.8340,   0.8267,  -1.6094]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -0.8457,   4.6406,  -8.3203,  ...,   7.0352,  -0.2612, -11.5078],\n",
    "        [ -1.3672,  -0.0645,  -6.3359,  ...,   6.5000,  -4.2773,  -2.7695],\n",
    "        [ -1.3770,   4.1680,  -5.0156,  ...,   5.2109,  -0.3672,  -5.2305],\n",
    "        ...,\n",
    "        [  1.3477,   8.8594,  -5.8477,  ...,  13.0391,  -3.8594,  -8.0312],\n",
    "        [ -0.3762,   2.9141,  -9.8281,  ...,   7.4648,  -6.6133,  -3.8262],\n",
    "        [ -3.9707,  -0.6641,  -9.2969,  ...,   8.1172,  -5.7773,   1.9570]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[-3.4531,  3.9688, -8.0156,  ..., 12.4297, -3.1367, -1.4688],\n",
    "        [-3.9707, -0.6641, -9.2969,  ...,  8.1172, -5.7773,  1.9570],\n",
    "        [-0.5391,  2.8242, -9.7734,  ...,  9.3359, -4.4141, -3.7930],\n",
    "        ...,\n",
    "        [-1.3770,  4.1680, -5.0156,  ...,  5.2109, -0.3672, -5.2305],\n",
    "        [ 1.0801,  6.0859, -6.0469,  ...,  8.4219, -3.5234, -4.1719],\n",
    "        [-1.7871,  1.7266, -2.0234,  ...,  5.3555,  1.8848, -9.6562]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ 1.5469e+00,  9.7188e+00, -5.1992e+00,  ...,  1.3539e+01,\n",
    "         -3.4102e+00, -7.7891e+00],\n",
    "        [-1.5508e+00,  2.6523e+00, -1.3125e+00,  ...,  6.6406e+00,\n",
    "          6.2402e-01, -1.0469e+01],\n",
    "        [-5.7617e-01,  6.0156e+00, -9.7500e+00,  ...,  4.2266e+00,\n",
    "          2.6523e+00, -1.3328e+01],\n",
    "        ...,\n",
    "        [-3.0645e+00,  3.5742e-01, -4.7578e+00,  ...,  1.2236e+00,\n",
    "         -6.0312e+00,  9.6484e-01],\n",
    "        [-4.0039e-02,  9.7656e-04, -2.5234e+00,  ...,  2.2480e+00,\n",
    "         -4.2891e+00, -2.1465e+00],\n",
    "        [ 7.2559e-01, -4.6055e+00, -4.2969e+00,  ..., -1.4922e+00,\n",
    "         -3.4102e+00, -7.1250e+00]], device='cuda:0', dtype=torch.float16,\n",
    "       grad_fn=<IndexBackward>), tensor([[ -1.4473,   6.5469,  -5.8359,  ...,   9.1797,   0.7363, -12.7344],\n",
    "        [  0.4316,   6.8398,  -3.7695,  ...,   8.2891,  -0.6855,  -4.7266],\n",
    "        [ -1.5508,   2.6523,  -1.3125,  ...,   6.6406,   0.6240, -10.4688],\n",
    "        ...,\n",
    "        [ -0.8535,  -1.8613,  -9.6875,  ...,  -0.2490,  -8.4688,  -1.3594],\n",
    "        [ -0.5762,   6.0156,  -9.7500,  ...,   4.2266,   2.6523, -13.3281],\n",
    "        [  0.0312,   4.6172,  -5.1484,  ...,   6.8750,   1.3037,  -6.1602]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -6.5703,  -1.0293,  -4.8359,  ...,  12.4453,  -1.2734, -14.6875],\n",
    "        [ -3.5469,  -4.2109,  -8.5000,  ...,   3.8672,  -5.2578,   5.4062],\n",
    "        [ -5.3555,   3.8789,  -9.3047,  ...,   6.9922,  -3.2441,  -5.2422],\n",
    "        [ -4.5469,   0.6055,  -1.0234,  ...,   6.7695,  -2.7734, -15.4141]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[  3.0723,   1.8584,  -5.8164,  ...,   8.8906, -10.0938,  -1.1562],\n",
    "        [ -3.5469,  -4.2109,  -8.5000,  ...,   3.8672,  -5.2578,   5.4062],\n",
    "        [ -5.3555,   3.8789,  -9.3047,  ...,   6.9922,  -3.2441,  -5.2422]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -3.4863,   2.0195, -13.5156,  ...,   2.1973,  -8.8281,   8.3047],\n",
    "        [ -9.6797,   5.9258, -12.8438,  ...,   2.2734,  -8.9844,   4.1055],\n",
    "        [ -7.2891,   4.0547,  -9.2031,  ...,   3.0625, -11.0625,   4.1172],\n",
    "        [ -8.1484,   3.4062,  -8.7031,  ...,   5.3789,  -5.0195,  -7.4141]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -1.8701,  -0.2500, -14.6250,  ...,  -0.1182,  -3.2012,   2.2051],\n",
    "        [  0.4907,   2.6855,  -7.6719,  ...,  -0.6313,  -6.2500,   2.9219],\n",
    "        [ -4.7578,   3.6211,  -8.0156,  ...,   7.0664,  -9.2969,   3.7773]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>), tensor([[ -9.0391,   4.9492,  -5.0625,  ...,   8.4609,  -5.6406,  -4.9844],\n",
    "        [ -5.5156,  -1.5967,  -7.1094,  ...,   6.3164,  -1.1758,  -7.3242],\n",
    "        [ -4.9766,   7.2422,  -5.6484,  ...,   0.8096,  -6.0156,  -4.0664],\n",
    "        ...,\n",
    "        [  0.4907,   2.6855,  -7.6719,  ...,  -0.6313,  -6.2500,   2.9219],\n",
    "        [ -0.8291,   7.7812,  -8.0000,  ...,   4.5352,  -2.8203, -10.3906],\n",
    "        [ -1.5312,   0.5195,  -7.0195,  ...,  -0.3774,  -0.0938,  -6.2500]],\n",
    "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward>)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[<InstanceData(\n",
    "\n",
    "    META INFORMATION\n",
    "    flip: False\n",
    "    pad_shape: (768, 1152)\n",
    "    ori_shape: (428, 640)\n",
    "    img_path: '/work/ovdet/data/coco/train2017/000000454577.jpg'\n",
    "    batch_input_shape: (768, 1152)\n",
    "    spanned_boxes: [[tensor([ 44.6425, 116.2690, 232.1075, 292.4810]), tensor([  0.0000, 116.2690, 232.1075, 235.8414]), tensor([ 44.6425, 172.9086, 232.1075, 235.8414])], [tensor([ 892.5469,  502.5794, 1133.3761,  752.1859]), tensor([1006.6239,  620.8141, 1133.3761,  752.1859]), tensor([1006.6239,  502.5794, 1133.3761,  752.1859])], [tensor([ 336.1976,    0.0000, 1148.0000,  686.0003]), tensor([ 720.7356,  199.4997, 1148.0000,  686.0003]), tensor([ 336.1976,    0.0000, 1148.0000,  686.0003])], [tensor([382.3273, 162.8153, 580.1727, 264.6923]), tensor([382.3273, 162.8153, 580.1727, 216.4347]), tensor([382.3273, 114.5577, 580.1727, 216.4347])], [tensor([ 49.8464, 355.5969, 262.2802, 592.7286]), tensor([  0.0000, 355.5969, 262.2802, 592.7286]), tensor([ 49.8464, 355.5969, 161.6536, 480.4031])], [tensor([769.1665, 161.5561, 944.8335, 217.6939]), tensor([ 769.1665,  111.0320, 1102.9338,  268.2180]), tensor([769.1665, 111.0320, 944.8335, 217.6939])], [tensor([  0.0000,  26.4310, 833.0006, 768.0000])], [tensor([551.3163, 123.9794, 722.6837, 273.6826]), tensor([551.3163, 123.9794, 876.9142, 202.7706]), tensor([397.0858, 123.9794, 876.9142, 273.6826])]]\n",
    "    img_id: 454577\n",
    "    scale_factor: (1.79375, 1.794392523364486)\n",
    "    seq_ids: [741, 741, 410, 410, 4, 782, 782, 746, 783, 783, 1214, 1214, 788, 1215, 1215, 1290, 1290, 1220, 1257, 1257, 10045, 10045, 7834, 7834, 1295, 10050, 10887, 10887, 10087, 10087, 10892, 10967, 10967, 10947, 10947, 18547, 18547]\n",
    "    flip_direction: None\n",
    "    normed_boxes: [[[tensor([[0.0000, 0.3214, 1.0000, 0.6786],\n",
    "                [0.0000, 0.6429, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 1.0000, 0.3571]]), tensor([[0.0000, 0.0000, 1.0000, 0.3571],\n",
    "                [0.0000, 0.6429, 1.0000, 1.0000],\n",
    "                [0.0000, 0.3214, 1.0000, 0.6786]])], [tensor([[0.1923, 0.0000, 1.0000, 0.5263],\n",
    "                [0.1923, 0.4737, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 0.2731, 0.5263]]), tensor([[0.0000, 0.0000, 0.2731, 0.5263],\n",
    "                [0.1923, 0.4737, 1.0000, 1.0000],\n",
    "                [0.1923, 0.0000, 1.0000, 0.5263]])], [tensor([[0., 0., 1., 1.]])]], [[tensor([[0.4737, 0.4737, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 0.5263, 0.5263]]), tensor([[0.0000, 0.0000, 0.5263, 0.5263],\n",
    "                [0.4737, 0.4737, 1.0000, 1.0000]])], [tensor([[0., 0., 1., 1.]])], [tensor([[0.0000, 0.4737, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 1.0000, 0.5263]]), tensor([[0.0000, 0.0000, 1.0000, 0.5263],\n",
    "                [0.0000, 0.4737, 1.0000, 1.0000]])]], [[tensor([[0.4737, 0.2908, 1.0000, 1.0000],\n",
    "                [0.0000, 0.2908, 0.5263, 1.0000],\n",
    "                [0.0000, 0.0000, 0.5263, 0.3617]]), tensor([[0.4737, 0.2908, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 0.5263, 0.3617],\n",
    "                [0.0000, 0.2908, 0.5263, 1.0000]])], [tensor([[0., 0., 1., 1.]])], [tensor([[0.4737, 0.0000, 1.0000, 0.3617],\n",
    "                [0.0000, 0.2908, 0.5263, 1.0000],\n",
    "                [0.4737, 0.2908, 1.0000, 1.0000]]), tensor([[0.0000, 0.2908, 0.5263, 1.0000],\n",
    "                [0.4737, 0.2908, 1.0000, 1.0000],\n",
    "                [0.4737, 0.0000, 1.0000, 0.3617]])]], [[tensor([[0.0000, 0.4737, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 1.0000, 0.5263]]), tensor([[0.0000, 0.0000, 1.0000, 0.5263],\n",
    "                [0.0000, 0.4737, 1.0000, 1.0000]])], [tensor([[0., 0., 1., 1.]])], [tensor([[0.0000, 0.4737, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 1.0000, 0.5263]]), tensor([[0.0000, 0.0000, 1.0000, 0.5263],\n",
    "                [0.0000, 0.4737, 1.0000, 1.0000]])]], [[tensor([[0.0000, 0.0000, 0.5263, 0.5263],\n",
    "                [0.4737, 0.0000, 1.0000, 0.5263],\n",
    "                [0.4737, 0.4737, 1.0000, 1.0000],\n",
    "                [0.0000, 0.4737, 0.5263, 1.0000]]), tensor([[0.4737, 0.4737, 1.0000, 1.0000],\n",
    "                [0.0000, 0.4737, 0.5263, 1.0000],\n",
    "                [0.4737, 0.0000, 1.0000, 0.5263],\n",
    "                [0.0000, 0.0000, 0.5263, 0.5263]])], [tensor([[0.5737, 0.0000, 1.0000, 0.5263],\n",
    "                [0.1901, 0.0000, 0.6163, 0.5263],\n",
    "                [0.0000, 0.4737, 0.2327, 1.0000],\n",
    "                [0.0000, 0.0000, 0.2327, 0.5263]]), tensor([[0.1901, 0.0000, 0.6163, 0.5263],\n",
    "                [0.0000, 0.4737, 0.2327, 1.0000],\n",
    "                [0.5737, 0.0000, 1.0000, 0.5263],\n",
    "                [0.0000, 0.0000, 0.2327, 0.5263]])], [tensor([[0., 0., 1., 1.]])]], [[tensor([[0., 0., 1., 1.]])], [tensor([[0.4737, 0.6429, 1.0000, 1.0000],\n",
    "                [0.0000, 0.3214, 0.5263, 0.6786],\n",
    "                [0.0000, 0.0000, 0.5263, 0.3571]]), tensor([[0.0000, 0.3214, 0.5263, 0.6786],\n",
    "                [0.0000, 0.0000, 0.5263, 0.3571],\n",
    "                [0.4737, 0.6429, 1.0000, 1.0000]])], [tensor([[0.0000, 0.4737, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 1.0000, 0.5263]]), tensor([[0.0000, 0.0000, 1.0000, 0.5263],\n",
    "                [0.0000, 0.4737, 1.0000, 1.0000]])]], [[tensor([[0., 0., 1., 1.]])]], [[tensor([[0.0000, 0.4737, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 1.0000, 0.5263]]), tensor([[0.0000, 0.0000, 1.0000, 0.5263],\n",
    "                [0.0000, 0.4737, 1.0000, 1.0000]])], [tensor([[0.4737, 0.0000, 1.0000, 1.0000],\n",
    "                [0.0000, 0.0000, 0.5263, 1.0000]]), tensor([[0.0000, 0.0000, 0.5263, 1.0000],\n",
    "                [0.4737, 0.0000, 1.0000, 1.0000]])], [tensor([[0.0000, 0.4737, 0.3571, 1.0000],\n",
    "                [0.6429, 0.0000, 1.0000, 0.5263],\n",
    "                [0.3214, 0.0000, 0.6786, 0.5263],\n",
    "                [0.3214, 0.4737, 0.6786, 1.0000]]), tensor([[0.0000, 0.4737, 0.3571, 1.0000],\n",
    "                [0.3214, 0.4737, 0.6786, 1.0000],\n",
    "                [0.3214, 0.0000, 0.6786, 0.5263],\n",
    "                [0.6429, 0.0000, 1.0000, 0.5263]])]]]\n",
    "    img_shape: (768, 1148)\n",
    "    box_ids: [[[4, 7, 1], [1, 7, 4], [1, 4, 0], [0, 4, 1], [4]], [[4, 0], [0, 4], [4], [4, 1], [1, 4]], [[4, 3, 0], [4, 0, 3], [4], [1, 3, 4], [3, 4, 1]], [[7, 4], [4, 7], [4], [4, 1], [1, 4]], [[4, 5, 8, 7], [8, 7, 5, 4], [5, 4, 6, 3], [4, 6, 5, 3], [4]], [[4], [8, 4, 1], [4, 1, 8], [4, 1], [1, 4]], [[4]], [[7, 4], [4, 7], [5, 4], [4, 5], [6, 5, 4, 7], [6, 7, 4, 5]]]\n",
    "\n",
    "    DATA FIELDS\n",
    "    bboxes: tensor([[  44.6425,  172.9086,  232.1075,  235.8414],\n",
    "                [  44.6425,  229.5481,  232.1075,  292.4810],\n",
    "                [  44.6425,  116.2690,  232.1075,  179.2019],\n",
    "                [  44.6425,  116.2690,  232.1075,  179.2019],\n",
    "                [  44.6425,  229.5481,  232.1075,  292.4810],\n",
    "                [  44.6425,  172.9086,  232.1075,  235.8414],\n",
    "                [  44.6425,  116.2690,  232.1075,  179.2019],\n",
    "                [  44.6425,  172.9086,  232.1075,  235.8414],\n",
    "                [   0.0000,  116.2690,   63.3890,  179.2019],\n",
    "                [   0.0000,  116.2690,   63.3890,  179.2019],\n",
    "                [  44.6425,  172.9086,  232.1075,  235.8414],\n",
    "                [  44.6425,  116.2690,  232.1075,  179.2019],\n",
    "                [  44.6425,  172.9086,  232.1075,  235.8414],\n",
    "                [1006.6239,  620.8141, 1133.3761,  752.1859],\n",
    "                [ 892.5469,  502.5794, 1019.2991,  633.9513],\n",
    "                [ 892.5469,  502.5794, 1019.2991,  633.9513],\n",
    "                [1006.6239,  620.8141, 1133.3761,  752.1859],\n",
    "                [1006.6239,  620.8141, 1133.3761,  752.1859],\n",
    "                [1006.6239,  620.8141, 1133.3761,  752.1859],\n",
    "                [1006.6239,  502.5794, 1133.3761,  633.9513],\n",
    "                [1006.6239,  502.5794, 1133.3761,  633.9513],\n",
    "                [1006.6239,  620.8141, 1133.3761,  752.1859],\n",
    "                [ 720.7356,  199.4997, 1148.0000,  686.0003],\n",
    "                [ 336.1976,  199.4997,  763.4620,  686.0003],\n",
    "                [ 336.1976,    0.0000,  763.4620,  248.1498],\n",
    "                [ 720.7356,  199.4997, 1148.0000,  686.0003],\n",
    "                [ 336.1976,    0.0000,  763.4620,  248.1498],\n",
    "                [ 336.1976,  199.4997,  763.4620,  686.0003],\n",
    "                [ 720.7356,  199.4997, 1148.0000,  686.0003],\n",
    "                [ 720.7356,    0.0000, 1148.0000,  248.1498],\n",
    "                [ 336.1976,  199.4997,  763.4620,  686.0003],\n",
    "                [ 720.7356,  199.4997, 1148.0000,  686.0003],\n",
    "                [ 336.1976,  199.4997,  763.4620,  686.0003],\n",
    "                [ 720.7356,  199.4997, 1148.0000,  686.0003],\n",
    "                [ 720.7356,    0.0000, 1148.0000,  248.1498],\n",
    "                [ 382.3273,  211.0728,  580.1727,  264.6923],\n",
    "                [ 382.3273,  162.8153,  580.1727,  216.4347],\n",
    "                [ 382.3273,  162.8153,  580.1727,  216.4347],\n",
    "                [ 382.3273,  211.0728,  580.1727,  264.6923],\n",
    "                [ 382.3273,  162.8153,  580.1727,  216.4347],\n",
    "                [ 382.3273,  162.8153,  580.1727,  216.4347],\n",
    "                [ 382.3273,  114.5577,  580.1727,  168.1772],\n",
    "                [ 382.3273,  114.5577,  580.1727,  168.1772],\n",
    "                [ 382.3273,  162.8153,  580.1727,  216.4347],\n",
    "                [  49.8464,  355.5969,  161.6536,  480.4031],\n",
    "                [ 150.4729,  355.5969,  262.2802,  480.4031],\n",
    "                [ 150.4729,  467.9225,  262.2802,  592.7286],\n",
    "                [  49.8464,  467.9225,  161.6536,  592.7286],\n",
    "                [ 150.4729,  467.9225,  262.2802,  592.7286],\n",
    "                [  49.8464,  467.9225,  161.6536,  592.7286],\n",
    "                [ 150.4729,  355.5969,  262.2802,  480.4031],\n",
    "                [  49.8464,  355.5969,  161.6536,  480.4031],\n",
    "                [ 150.4729,  355.5969,  262.2802,  480.4031],\n",
    "                [  49.8464,  355.5969,  161.6536,  480.4031],\n",
    "                [   0.0000,  467.9225,   61.0271,  592.7286],\n",
    "                [   0.0000,  355.5969,   61.0271,  480.4031],\n",
    "                [  49.8464,  355.5969,  161.6536,  480.4031],\n",
    "                [   0.0000,  467.9225,   61.0271,  592.7286],\n",
    "                [ 150.4729,  355.5969,  262.2802,  480.4031],\n",
    "                [   0.0000,  355.5969,   61.0271,  480.4031],\n",
    "                [  49.8464,  355.5969,  161.6536,  480.4031],\n",
    "                [ 769.1665,  161.5561,  944.8335,  217.6939],\n",
    "                [ 927.2668,  212.0801, 1102.9338,  268.2180],\n",
    "                [ 769.1665,  161.5561,  944.8335,  217.6939],\n",
    "                [ 769.1665,  111.0320,  944.8335,  167.1698],\n",
    "                [ 769.1665,  161.5561,  944.8335,  217.6939],\n",
    "                [ 769.1665,  111.0320,  944.8335,  167.1698],\n",
    "                [ 927.2668,  212.0801, 1102.9338,  268.2180],\n",
    "                [ 769.1665,  161.5561,  944.8335,  217.6939],\n",
    "                [ 769.1665,  111.0320,  944.8335,  167.1698],\n",
    "                [ 769.1665,  111.0320,  944.8335,  167.1698],\n",
    "                [ 769.1665,  161.5561,  944.8335,  217.6939],\n",
    "                [   0.0000,   26.4310,  833.0006,  768.0000],\n",
    "                [ 551.3163,  194.8914,  722.6837,  273.6826],\n",
    "                [ 551.3163,  123.9794,  722.6837,  202.7706],\n",
    "                [ 551.3163,  123.9794,  722.6837,  202.7706],\n",
    "                [ 551.3163,  194.8914,  722.6837,  273.6826],\n",
    "                [ 705.5469,  123.9794,  876.9142,  202.7706],\n",
    "                [ 551.3163,  123.9794,  722.6837,  202.7706],\n",
    "                [ 551.3163,  123.9794,  722.6837,  202.7706],\n",
    "                [ 705.5469,  123.9794,  876.9142,  202.7706],\n",
    "                [ 397.0858,  194.8914,  568.4531,  273.6826],\n",
    "                [ 705.5469,  123.9794,  876.9142,  202.7706],\n",
    "                [ 551.3163,  123.9794,  722.6837,  202.7706],\n",
    "                [ 551.3163,  194.8914,  722.6837,  273.6826],\n",
    "                [ 397.0858,  194.8914,  568.4531,  273.6826],\n",
    "                [ 551.3163,  194.8914,  722.6837,  273.6826],\n",
    "                [ 551.3163,  123.9794,  722.6837,  202.7706],\n",
    "                [ 705.5469,  123.9794,  876.9142,  202.7706]], device='cuda:0')\n",
    ") at 0x7f7e17b7cc50>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[[4], [1, 4, 2], [4, 1, 2], [1, 4], [4, 1]]]\n",
    "[[4, 8], [8, 4], [4, 2], [2, 4], [4]]]\n",
    "\n",
    "[[[4, 0], [0, 4], [5, 4], [4, 5], [4]],\n",
    " [[3, 4], [4, 3], [3, 4, 8], [4, 3, 8], [4]]]\n",
    "tensor([[1.0000, 0.0000, 0.0030, 0.0030, 0.0100, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 1.0000, 0.0030, 0.0030, 0.0100, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0030, 0.0030, 1.0000, 0.0000, 0.0100, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0030, 0.0030, 0.0000, 1.0000, 0.0100, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0100, 0.0100, 0.0100, 0.0100, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0065, 0.0065, 0.0100, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0065, 0.0065, 0.0100, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0065, 0.0065, 1.0000, 0.0000, 0.0100, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0065, 0.0065, 0.0000, 1.0000, 0.0100, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0100, 0.0100, 0.0100, 0.0100, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0', dtype=torch.float16)\n",
    "\n",
    "\n",
    "[[[4], [4, 3], [3, 4], [4, 0, 5], [4, 5, 0]],\n",
    " [[4], [2, 4], [4, 2], [1, 4], [4, 1]],\n",
    " [[7, 8, 4, 1], [8, 7, 1, 4], [4], [7, 0, 5, 1, 2, 4], [0, 2, 1, 4, 7, 5]],\n",
    " [[4], [5, 4], [4, 5], [1, 4], [4, 1]],\n",
    " [[3, 4], [4, 3], [4, 3, 1], [4, 1, 3], [4, 6, 7], [6, 7, 4]]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
